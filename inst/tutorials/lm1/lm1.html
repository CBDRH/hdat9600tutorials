<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="false" />
<meta name="allow-skip" content="true" />

<title>HDAT9600 Linear Models 1</title>


<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>

<!-- taken from https://github.com/rstudio/rmarkdown/blob/67b7f5fc779e4cfdfd0f021d3d7745b6b6e17149/inst/rmd/h/default.html#L296-L362 -->
<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>
<!-- end tabsets -->


<link rel="stylesheet" href="css/tutorials.css" type="text/css" />

</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<p><img src="../images/UNSW_2017_Big_Data_landscape.jpg" style="width:75.0%" /></p>
<div id="section-introduction" class="section level2">
<h2>Introduction</h2>
<p><span class="copyright">© Copyright 2021 UNSW Sydney. All rights reserved except where otherwise stated.</span></p>
<p>This chapter, and the two chapters that follow it, are closely based on the first set text for the HDAT9600 course: Julian J. Faraway. Linear Models using R. 2nd Edition. CRC Press. This text is referred to as <em>Faraway LMwR</em> in these notes. Although you are encouraged to use this text for additional readings if you wish, this is not essential — these notes have abstracted all the salient points from this text for the content covered by this course.</p>
</div>
<div id="section-nomenclature" class="section level2">
<h2>1. Nomenclature</h2>
<p>Linear regression models are mathematical models used to characterise, investigate and/or explain the relationship between:</p>
<ul>
<li>a single outcome variable, <span class="math inline">\(Y\)</span>, which is variously called the <em>response</em>, <em>outcome</em>, <em>output</em>, <em>label</em> (in machine learning contexts) or the <em>dependent</em> variable; and</li>
<li>one or more variables <span class="math inline">\(X_1, ..., X_p\)</span>, where <em>p</em> is the number of such variables, which are variously called <em>predictor</em>, <em>explanatory</em>, <em>inputs</em>, <em>features</em> (again, in machine learning contexts) or <em>independent</em> variables.</li>
</ul>
<p>Which nomenclature is used tends to depend on the field or discipline, but there is a lot of cross-over. In general it is better to avoid using the terms <em>dependent</em> and <em>independent</em> due to confusion with the other statistical uses of these terms, meaning <em>correlated</em> or <em>uncorrelated</em> respectively.</p>
<p>The term <em>regression analysis</em> is often used to refer to the fitting of linear models to data, although it also encompasses non-linear models.</p>
<p>The term <em>regression</em> stems from the work of <a href="https://en.wikipedia.org/wiki/Francis_Galton">Francis Galton</a>, who was a half-cousin of Charles Darwin, and who coined the term <em>regression to mediocrity</em> in 1875. Galton used a form of linear model to investigate the relationship between the heights of parents and their offspring, which he termed “the regression effect”. The “regression” term came to be applied to all linear models, and then to non-linear and generalised linear models as well. As such, the term is somewhat archaic, but nonetheless still widely used, and we still speak of “regressing X on Y” and “fitting regression models to data”. “Statistical models” is probably a better, more modern term to use (and hence the name for this course).</p>
<p>When there is only one <em>X</em> variable (that is, <em>p</em> = 1), then the term <em>simple regression</em> is sometimes used, but when <em>p</em> &gt; 1, then the term <em>multiple regression</em> or <em>multivariate regression</em> is used. <em>Multivariable regression</em> is sometimes (confusingly) used to refer to regressions involving more than one outcome or response variable, but again it is better to avoid this term.</p>
<p>In <em>linear regression</em>, which we will be examining in chapters 2, 3 and 4 of this course, the outcome or response variable (we will mainly use <em>outcome variable</em> henceforth) must be a continuous variable - that is, a variable that can take an infinite number of ordered values, as opposed to a discrete variable that can only take a finite number of values. That doesn’t mean that the outcome variable can’t be be constrained - for example, the heights of people is a continuous variable (subject to the limits of resolution of the measurement apparatus used to ascertain height), but no-one has a negative height, nor does anyone have a height greater than 3 metres.</p>
<p><em>Explanatory (predictor) variables</em> in a linear (and other) regression model do <strong>not</strong> have to be continuous - they can be continuous, discrete (eg integers) or categorical (qualitative). If all the predictors are categorical, then the term <em>analysis of variance</em> (ANOVA) is often used, and if the predictors are a mixture of categorical and continuous variables, then the term <em>analysis of covariance</em> (ANCOVA) is sometimes used, although both of these are just special cases of linear regression. We will cover these briefly in a later chapter, because they use some special terminology that you will almost certainly encounter at some stage.</p>
<div id="section-quiz" class="section level3">
<h3>Quiz</h3>
<div class="panel panel-default">
<div data-label="question-1" class="tutorial-question panel-body">
<div id="question-1-answer_container" class="shiny-html-output"></div>
<div id="question-1-message_container" class="shiny-html-output"></div>
<div id="question-1-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
</div>
</div>
<div id="section-the-purposes-of-statistical-regression-models" class="section level2">
<h2>2. The purposes of statistical (regression) models</h2>
<p>There are two types of objective for regression models:</p>
<ul>
<li><strong>prediction</strong> of future or unseen outcomes (responses) given specified or known values of predictor variables;</li>
<li><strong>explanation</strong> or characterisation of the relationship between explanatory variables and the outcome, often with a view to making inferences about hypothesised causal relationships.</li>
</ul>
<p>A given regression model may serve both objectives, although when specifying, fitting and testing models, different appraoches may be taken depending on which of these two objectives, prediction or explanation, is most important. Of course, it is possible to fit more than one model to a particular data set, and it may be that distinct models are required to best achieve each of these objectives.</p>
<p>It is also worth bearing in mind the <a href="https://en.wikipedia.org/wiki/All_models_are_wrong">aphorism attributed to George Box</a>:</p>
<blockquote>
<p>All models are wrong, but some are useful.</p>
</blockquote>
</div>
<div id="section-definition-of-the-linear-model" class="section level2">
<h2>3. Definition of the linear model</h2>
<p>If we want to model an outcome (response) <em>Y</em> in terms of, say, three predictors, <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, and <span class="math inline">\(X_3\)</span>, a very general form for the model might be:</p>
<p><span class="math display">\[ Y = f(X_1, X_2, X_3) + \epsilon \]</span></p>
<p>where <span class="math inline">\(f()\)</span> is some function and <span class="math inline">\(\epsilon\)</span> is the irreducible error (meaning that it is unavoidable “noise” and cannot be explained by any function of the predictor variables — of course, the “error” may be explainable, at least in part, by unobserved variables — other things that we don’t have information about).</p>
<p>However, in this definition, the function <span class="math inline">\(f()\)</span> can take an infinite number of forms, and just three predictor variables will not be enough to estimate what its form actually is. Thus, in practice we restrict the form that the function <span class="math inline">\(f()\)</span> can take, and in a <em>linear</em> model, <span class="math inline">\(f()\)</span> is a linear function of the predictor variables, such as:</p>
<p><span class="math display">\[ Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_3 + \epsilon \]</span> where <span class="math inline">\(\beta_i, i = 0,1,2,3\)</span> are unknown <em>parameters</em>. Note the statistical use of the term <em>parameter</em> here to refer to the <span class="math inline">\(\beta_i\)</span> co-efficients — in engineering or computer science, the term <em>parameters</em> is often used to refer to the variables, <span class="math inline">\(X_1...X_3\)</span> in our equation. Also note that the <span class="math inline">\(\beta_0\)</span> parameter has a special name in statistics, the <em>intercept term</em>, or just the <em>intercept</em> for short.</p>
<p>So, by restricting the possible form of our model function like this, we only need to estimate four unknown parameters (<span class="math inline">\(\beta_0...\beta_3\)</span>) from our data (which comprises <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_1...X_3\)</span> in this example). This makes estimation of our model much easier, as we shall see.</p>
<div id="section-linear-models-must-have-linear-parameters-not-linear-predictor-variables" class="section level3">
<h3>Linear models must have linear parameters, not linear predictor variables</h3>
<p>The strictly linear form of our model perhaps seems a bit too restrictive, since it would seem to imply a purely linear relationship between our predictors and the outcome, but in fact, it is not that constrained. The reason is that in a linear model, only the <em>parameters</em> enter the model equation <em>linearly</em> — the predictors themselves <strong>do not</strong> need to be linear.</p>
<p>For example, this is also a linear model:</p>
<p><span class="math display">\[ Y = \beta_0 + \beta_1X_1 + \beta_2log(X_2) + \beta_3X_1X_2 + \epsilon \]</span></p>
<p>but this is <strong>not</strong> a linear model:</p>
<p><span class="math display">\[ Y = \beta_0 + \beta_1X_1^{\beta_2} + \epsilon \]</span></p>
<p>Thus, linear models are a lot more flexible than many people assume, and they can readily model non-linear relationships between predictors and outcome variables.</p>
</div>
<div id="section-where-do-linear-models-come-from" class="section level3">
<h3>Where do linear models come from?</h3>
<p>This is a reasonable question. Do they just magically spring from the mind of the data scientist, or are there principles and methods for creating them?</p>
<p>In general, there are three ways a linear (or any) statistical model might be created:</p>
<ol style="list-style-type: decimal">
<li>Based on some known or well-understood physical, chemical, economic or even social theory. For example, <a href="https://en.wikipedia.org/wiki/Hooke&#39;s_law">Hooke’s law</a> states that the extension of a spring is proportional to the weight attached to it and thus it can be modelled with a linear model of the form:</li>
</ol>
<p><span class="math display">\[ Y = \beta_0 + \beta_1X_1 + \epsilon \]</span> where <span class="math inline">\(Y\)</span> is a vector of measured lengths of the spring, <span class="math inline">\(\beta_0\)</span> is the length of the spring at rest without any weight attached, <span class="math inline">\(X_1\)</span> is a vector of weights attached to the spring, and <span class="math inline">\(\epsilon\)</span> is the (possible quite small) random error that is inevitable whenever any experimental apparatus is repeatedly measured.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Experience with past data — if particular forms of model fitted similar data quite well in the past, it is natural to try such models again.</p></li>
<li><p>Using <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> — no definitive theory or prior idea of what form the model should take exists, and thus trial-and-error is used to try to arrive at a satisfactory model.</p></li>
</ol>
</div>
<div id="section-quiz-1" class="section level3">
<h3>Quiz</h3>
<div class="panel panel-default">
<div data-label="question-2" class="tutorial-question panel-body">
<div id="question-2-answer_container" class="shiny-html-output"></div>
<div id="question-2-message_container" class="shiny-html-output"></div>
<div id="question-2-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
</div>
</div>
<div id="section-matrix-representation-of-linear-models" class="section level2">
<h2>4. Matrix representation of linear models</h2>
<p>Although we will not delve <strong>too</strong> deeply into the <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">matrix algebra</a> involved in fitting linear models to data, it is nonetheless useful to review the mathematical matrix representation of our data.</p>
<p>If we have data which contains an outcome variable <em>Y</em> and three predictors <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span> and <span class="math inline">\(X_3\)</span>, we can represent it in tabular form like this:</p>
<p><span class="math display">\[
 \begin{matrix}
  y_1 &amp; x_{11} &amp; x_{12} &amp; x_{13} \\
  y_2 &amp; x_{21} &amp; x_{22} &amp; x_{23} \\
  \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
  y_n &amp; x_{n1} &amp; x_{n2} &amp; x_{n3} \\
 \end{matrix}
\]</span></p>
<p>where <em>n</em> is the number or observations (cases, rows) in the dataset.</p>
<p>We have seen that we can write a linear model to fit these data as:</p>
<p><span class="math display">\[ y_i = \beta_0 + \beta_1x_{i1}  + \beta_2x_{i2} + \beta_3x_{i3} + \epsilon_i  \]</span></p>
<p>where <span class="math inline">\(i = 1, ..., n\)</span>.</p>
<p>This can also be more compactly written using matrix/vector representaton:</p>
<p><span class="math display">\[ \mathbf{y} = \mathbf{X\beta} + \epsilon \]</span></p>
<p>where <span class="math inline">\(\mathbf{y} =(y_1,...,y_n)^T, \epsilon = (\epsilon_1, ..., \epsilon_n)^T, \beta = (\beta_0,...,\beta_3)^T\)</span> and :</p>
<p><span class="math display">\[
\mathbf{X}  =
 \begin{pmatrix}
  1 &amp; x_{11} &amp; x_{12} &amp; x_{13} \\
  1 &amp; x_{21} &amp; x_{22} &amp; x_{23} \\
  \vdots  &amp; \vdots  &amp; \vdots &amp; \vdots  \\
  1 &amp; x_{n1} &amp; x_{n2} &amp; x_{n3}
 \end{pmatrix}
\]</span></p>
<p>Note that the column of ones incorporates the <em>intercept</em> term, <span class="math inline">\(\beta_0\)</span>. We’ll explore the interpretation of the intercept term, and the other parameter estimates, in the next chapter.</p>
<p>With this notation, the simplest model we can represent is the <em>null model</em>, also sometimes called an <em>intercept-only</em> model, which has no predictors and just the overall mean plus the errors <span class="math inline">\(y = \mu + \epsilon\)</span>:</p>
<p><span class="math display">\[
\begin{pmatrix}
  y_1 \\
  \vdots \\
  y_n
 \end{pmatrix}
 =
 \begin{pmatrix}
  1  \\
  \vdots  \\
  1
 \end{pmatrix} \mu
 +
\begin{pmatrix}
  \epsilon_1 \\
  \vdots \\
  \epsilon_n
 \end{pmatrix}
\]</span></p>
<p>Note that <span class="math inline">\(E(\epsilon) = 0\)</span>, that is, the expectation (mean) of the errors is zero - otherwise, any non-zero expectation of the errors could just be absorbed into (added to) the mean <span class="math inline">\(\mu\)</span> to get a zero expectation of <span class="math inline">\(\epsilon\)</span>.</p>
</div>
<div id="section-estimation-of-beta" class="section level2">
<h2>5. Estimation of <span class="math inline">\(\beta\)</span></h2>
<p>The regression model <span class="math inline">\(\mathbf{y} = \mathbf{X\beta} + \epsilon\)</span> partitions the outcome variable <span class="math inline">\(\mathbf{y}\)</span> into a systematic component <span class="math inline">\(\mathbf{X\beta}\)</span> and a random component <span class="math inline">\(\epsilon\)</span>. To fit the model to our data, we need to find values for <span class="math inline">\(\beta\)</span>, which, remember, is a vector of parameters <span class="math inline">\((\beta_0,...,\beta_3)^T\)</span>, such that <span class="math inline">\(\mathbf{\beta}\)</span> explains as much of the variation in the outcome variable as possible.</p>
<p>If we consider this geometrically, the outcome <span class="math inline">\(\mathbf{y}\)</span> lies in an <em>n</em>-dimensional space, while <span class="math inline">\(\mathbf{\beta}\)</span> lies in a <em>p</em>-dimensional space, where <em>p</em> is the number of predictors (including the intercept).</p>
<p>The problem is to find the vector <span class="math inline">\(\mathbf{\beta}\)</span> (that is, all the <span class="math inline">\(\mathbf{\beta}\)</span> estimates for the model, <span class="math inline">\(\beta_0,...,\beta_3\)</span>), such that <span class="math inline">\(\mathbf{X\beta}\)</span> (that is, the linear summation of the matrix of all the predictor data, <span class="math inline">\(\mathbf{X}\)</span>, multiplied by the vector of <span class="math inline">\(\mathbf{\beta}\)</span> estimates) is as close to <span class="math inline">\(\mathbf{y}\)</span> (the vector of outcomes) as possible. The best choices for <span class="math inline">\(\mathbf{\beta}\)</span> are known as the <span class="math inline">\(\mathbf{\beta}\)</span> <em>estimates</em>, or the <em>regression co-efficients</em>, and are denoted <span class="math inline">\(\mathbf{\widehat{\beta}}\)</span>. The responses or outcomes predicted by the model, also known as the <em>predicted</em> or <em>fitted</em> values, are denoted <span class="math inline">\(\mathbf{\widehat{y}} = \mathbf{X\widehat{\beta}}\)</span>. The difference between the actual outcome (response) and the predicted outcome is called the <em>residual</em> (or the <em>residuals</em>) and is denoted <span class="math inline">\(\widehat{\epsilon}\)</span>.</p>
<p>Put another way, the purpose of the model is to represent, as accurately as possible given the inherent limitations of the model, something complex, <em>y</em>, which is the outcome (response) data and which is <em>n</em>-dimensional (where <em>n</em> is the number of observations or rows in our data set), in terms of something much simpler: the model, which is <em>p</em>-dimensional, where <em>p</em> is the number of parameters in our model. In a successful model, the essential structure of our data should be captured in the <em>p</em> dimensions, leaving just purely random variation in the residuals <span class="math inline">\(\widehat{\epsilon}\)</span> which lie in an <em>(n - p)</em>-dimensional space.</p>
<p>Thus we have:</p>
<table>
<thead>
<tr class="header">
<th align="right"></th>
<th>\</th>
<th></th>
<th>\</th>
<th align="right"></th>
<th>\</th>
<th></th>
<th>\</th>
<th align="right"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Data</td>
<td>\</td>
<td>=</td>
<td>\</td>
<td align="right">Systematic structure</td>
<td>\</td>
<td>+</td>
<td>\</td>
<td align="right">Random variation</td>
</tr>
<tr class="even">
<td align="right"><em>n</em> dimensions</td>
<td>\</td>
<td>=</td>
<td>\</td>
<td align="right"><em>p</em> dimensions</td>
<td>\</td>
<td>+</td>
<td>\</td>
<td align="right"><em>(n - p)</em> dimensions</td>
</tr>
</tbody>
</table>
<p>So, how do we estimate <span class="math inline">\(\beta\)</span>?</p>
</div>
<div id="section-least-squares-estimation" class="section level2">
<h2>6. Least squares estimation</h2>
<div class="anxiety">
<h3 id="section-oh-no-maths">Oh no, maths!</h3>
<p>This section contains quite a bit of maths. Don’t skip it, but don’t worry if you don’t follow every step along the way — you won’t be examined or assessed on your understanding of it. We have included it to reinforce the point that statistical model fitting is not some kind of magic, and that the steps involve make both mathematical and intuitive sense.</p>
</div>
<p>The oldest and still widely-used method of estimating <span class="math inline">\(\beta\)</span> for linear models is the least squares method, also known as <em>ordinary least squares</em> or OLS.</p>
<p>Recall that we can write our linear model as:</p>
<p><span class="math display">\[ y = X\beta + \epsilon \]</span></p>
<p>where we additionally assume that <span class="math inline">\(\epsilon\)</span> has a normal distribution with mean zero and variance <em>I</em>:</p>
<p><span class="math display">\[ \epsilon \thicksim N(0, I) \]</span></p>
<p>For some estimate of the model’s parameters, <span class="math inline">\(\widehat{\beta}\)</span>, the model’s prediction errors, <span class="math inline">\(\epsilon\)</span>, also known as the <em>residuals</em>, are:</p>
<p><span class="math display">\[ \widehat{\epsilon} = \mathbf{y} - \mathbf{X\widehat{\beta}} \]</span></p>
<p>We define the best estimate of <span class="math inline">\(\beta\)</span> as the one which minimises the sum of the squared errors:</p>
<p><span class="math display">\[
\begin{align}
  \sum{\epsilon_i^2} = \epsilon^T\epsilon &amp;= (y - X\beta)^T(y - X\beta) \\
  &amp;= y^Ty - y^T(X\widehat{\beta}) - (X\widehat{\beta})^Ty + (X\widehat{\beta})^T(X\widehat{\beta}) \\
  &amp;= y^Ty - (X\widehat{\beta})^Ty - (X\widehat{\beta})^Ty + (X\widehat{\beta})^T(X\widehat{\beta}) \\
  &amp;= y^Ty - 2(X\widehat{\beta})^Ty + (X\widehat{\beta})^T(X\widehat{\beta}) \\
  &amp;= y^Ty - 2\widehat{\beta}^TX^Ty  + \widehat{\beta}^TX^TX\widehat{\beta} \\
\end{align}
\]</span></p>
<p>To determine the parameters, <span class="math inline">\(\widehat{\beta}\)</span>, we minimize the sum of squared residuals with respect to the parameters, by setting them to zero, and taking the derivative with respect to <span class="math inline">\(\beta\)</span>. We find that <span class="math inline">\(\widehat{\beta}\)</span> satisfies:</p>
<p><span class="math display">\[ X^TX\widehat{\beta} = X^Ty \]</span></p>
<p>These are called the <em>normal equations</em>.</p>
<div class="aside">
<h3 id="section-why-are-they-called-the-normal-equations">Why are they called the <em>normal</em> equations?</h3>
<p>The use of the term <em>normal</em> in <em>normal equations</em> is nothing to do with the normal probability distribution. Rather, <em>normal</em> is here as a bit of jargon from linear algebra — <span class="math inline">\(X^TX\)</span> is a <a href="http://mathworld.wolfram.com/NormalMatrix.html"><em>normal matrix</em></a> and <span class="math inline">\(y - \widehat{\beta}X\)</span> is <em>normal</em> to the range of <span class="math inline">\(X\)</span>.</p>
</div>
<p>Now, provided that <span class="math inline">\(X^TX\)</span> is invertible (recall matrix inversion from Chapter 1), we can do some re-arrangment to obtain the results:</p>
<p><span class="math display">\[
\begin{align}
\begin{split}
\widehat{\beta} &amp; = (X^TX)^{-1}X^Ty \\
X\widehat{\beta} &amp; = X(X^Tx)^{-1}X^Ty \\
\widehat{y} &amp; = Hy
\end{split}
\end{align}
\]</span></p>
<p>where <span class="math inline">\(H = X(X^TX)^{-1}X^T\)</span> and is called the <em>hat matrix</em>. Geometrically it is the orthogonal projection of <em>y</em> onto the space spanned by <em>X</em> (that statement will make more sense if have you watched the 3Blue1Brown videos mentioned in Chapter 1). The hat matrix is an <span class="math inline">\(n \times n\)</span> matrix, where <span class="math inline">\(n\)</span> is the number of observations (cases) in the dataset, and thus it can be rather large for some larger datasets. However, the hat matrix <span class="math inline">\(H\)</span> can be used to calculate several useful quantities.</p>
<p>The <em>predicted values</em> (also often called the <em>fitted values</em>) of <em>y</em> from the model are <span class="math inline">\(\widehat{y} = Hy = X\widehat{\beta}\)</span>.</p>
<p>The <em>residual sum of squares</em> (RSS) is <span class="math inline">\(\widehat{\epsilon}^T\widehat{\epsilon} = y^T(I - H)^T(I - H)y = y^T(I - H)y\)</span>. In words, the RSS is the sum of the squares of the differences between each value of <em>y</em> and each corresponding predicted value of <em>y</em>. This difference is very often referred to by the shorthand name of “<em>the error</em>” or “<em>the errors</em>”.</p>
<p>It can be shown mathematically that this least squares estimate is the best possible estimate of <span class="math inline">\(\beta\)</span> when the errors <span class="math inline">\(\epsilon\)</span> are uncorrelated and have equal variance. This assumption is often called the <em>i.i.d.</em> (or <em>iid</em>) assumption, standing for <em>independent and identically distributed</em>, meaning that each observation (row, case) has no effect on or relationship to other observations (independence) and that their errors (their non-systematic, random variation components) all have the same variance, a property also known as <a href="https://en.wikipedia.org/wiki/Homoscedasticity">homoscedasticity</a>.</p>
<p>Under i.i.d. circumstances, <span class="math inline">\(\widehat{\beta}\)</span> is an unbiased estimator and has variance <span class="math inline">\((X^TX)^{-1}\sigma^2\)</span> (provided that <span class="math inline">\(\textrm{var} \epsilon = \sigma^2I\)</span> — that is, that the errors have equal variance). Because <span class="math inline">\(\widehat{\beta}\)</span> is a matrix, its variance is also a matrix.</p>
<p>We also need to estimate <span class="math inline">\(\sigma^2\)</span>. Recall that <em>n</em> is the number of observations (cases) in the dataset, and <em>p</em> is the number of estimator variables in the model being fitted. It can be shown that an unbiased estimator of <span class="math inline">\(\sigma^2\)</span> is:</p>
<p><span class="math display">\[
\widehat{\sigma}^2 = \frac{\widehat{\epsilon}^T\widehat{\epsilon}}{n - p} = \frac{\textrm{RSS}}{n - p}
\]</span></p>
<p><span class="math inline">\(n - p\)</span> is called the <em>degrees-of-freedom</em> (often without the hyphens) of the model, usually abbreviated to just <em>df</em>.</p>
<p>Finally, the standard error for a particular predictor variable (the <span class="math inline">\(i\)</span>th predictor variable) in <span class="math inline">\(\widehat{\beta}\)</span> is:</p>
<p><span class="math display">\[
se(\widehat{\beta}_{i}) = \sqrt{(X^TX)_{ii}^{-1}}\widehat{\sigma}
\]</span></p>
<p>Phew! Enough maths for now…</p>
</div>
<div id="section-a-practical-example" class="section level2">
<h2>7. A practical example</h2>
<p>Let’s examine the example provided by Faraway, which concerns the numbers of species of animals found on various of the Galápagos Islands (which were made famous by Charles Darwin). It isn’t a health-related dataset, but it is nicely suited to exploration of these inital concepts, so we will make use of it. In the dataset there are 30 observations (each observation is an island) and seven variables. We can load the data set and examine the first six rows thus:</p>
<pre class="r"><code>data(gala, package=&quot;faraway&quot;)
head(gala)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Species"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Endemics"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Area"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Elevation"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Nearest"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["Scruz"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["Adjacent"],"name":[7],"type":["dbl"],"align":["right"]}],"data":[{"1":"58","2":"23","3":"25.09","4":"346","5":"0.6","6":"0.6","7":"1.84","_rn_":"Baltra"},{"1":"31","2":"21","3":"1.24","4":"109","5":"0.6","6":"26.3","7":"572.33","_rn_":"Bartolome"},{"1":"3","2":"3","3":"0.21","4":"114","5":"2.8","6":"58.7","7":"0.78","_rn_":"Caldwell"},{"1":"25","2":"9","3":"0.10","4":"46","5":"1.9","6":"47.4","7":"0.18","_rn_":"Champion"},{"1":"2","2":"1","3":"0.05","4":"77","5":"1.9","6":"1.9","7":"903.82","_rn_":"Coamano"},{"1":"18","2":"11","3":"0.34","4":"119","5":"8.0","6":"8.0","7":"1.84","_rn_":"Daphne.Major"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>The row names are the names of each island in the Galápagos group, the <code>Species</code> column is the number of species found on each island, <code>Area</code> is the area of each island in square kilometers, <code>Elevation</code> is the highest point of the island in metres, <code>Nearest</code> is the distance from the nearest island, in kilometres, <code>Scruz</code> is the distance in kilometres from the main island of <code>Santa Cruz</code>, <code>Adjacent</code> is the area of the nearest island in square kilometres. <code>Endemics</code> is the number of endemic species on each island, but we won’t use that variable in this example.</p>
<p>We can fit a linear model to these data using the <code>lm()</code> function that come with base <span class="math inline">\(\textsf{R}\)</span>. The model can be specified as arguments to this function in two different ways, but the easiest to use is the <em>formula</em> interface, as shown below. Notice that <em>Species</em> is our outcome variable (<em>y</em>) and appears to the left of the tilde (~), while our predictor variables are specified to the right of the tilde. Notice also that we assign the name <code>lmod</code> to the output object of this model. The output object is actually a list of values relating to the model, but we can get a convenient print-out of some of those values using the <code>summary()</code> function on the model output object.</p>
<p>So, the code looks like this — run it and examine the output:</p>
<div class="tutorial-exercise" data-label="fit_gala_linear_model" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmod &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)
summary(lmod)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>There are quite a few results reported in this output, and we’ll examine them in more detail later, but for now, notice the <em>Estimate</em> column, which lists the <span class="math inline">\(\widehat{\beta}\)</span> estimates for each predictor variable, with <em>(Intercept)</em> being the estimate of <span class="math inline">\(\beta_0\)</span>.</p>
<div class="aside">
<h3 id="section-in-real-life-we-would-have-done-eda-first">In real life, we would have done EDA first…</h3>
<p>In real life, we would have thoroughly explored our dataset first by performing an exploratory data analysis (EDA), visualising a) the distribution of each of the variables in it in a univariate fashion, and b) looking at the relationships between pairs of variables. Remember we are not only interested in bivariate analyses of each predictor variable and the outcome, but also bivariate analysis of each pair of predictors themselves. This latter point is important in detecting potential collinearity (which we will discuss in the next chapter).</p>
<p>We are omitting this absolutely essential EDA step in this example, as we have a lot of material to cover, but <strong>don’t skip it</strong> in real life! As a reminder of the EDA importance, we will practice this in Chapter 2 assessable exercise.</p>
<p>Aside: have a look at this <a href="http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html">Datasaurus</a> graph to convince yourself of the importance of graphing your data.</p>
</div>
<p>The <code>lm()</code> function conveniently calculates almost everything we might need when fitting a linear model, using the best practice calculation methods for model fitting (discussed below). Nonetheless, we can also calculate <span class="math inline">\(\beta\)</span> estimates ourselves, if we wish. Let’s do that now.</p>
<p>First, we can extract the matrix of predictors, <em>X</em>, using the <code>model.matrix()</code> function:</p>
<div class="tutorial-exercise-support" data-label="get_gala_model_matrix-set-up" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmod &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)</code></pre>
</div>
<div class="tutorial-exercise" data-label="get_gala_model_matrix" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>X &lt;- model.matrix(lmod)
X</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"get_gala_model_matrix-set-up","exercise.checker":"NULL"}</script>
</div>
<p>and the outcome <em>y</em>:</p>
<div class="tutorial-exercise" data-label="get_gala_response_column" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>y &lt;- gala$Species
y</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>So, referring back to the formulas <span class="math inline">\(\widehat{\beta} = (X^TX)^{-1}X^Ty\)</span>, we first calculate <span class="math inline">\((X^TX)^{-1}\)</span>. Recall from HDAT9600 Chapter 1 material that <code>t()</code> returns the transpose of a matrix (i.e <code>t(X)</code> returns <span class="math inline">\(X^T\)</span>), that <code>%*%</code> does matrix multiplication, and <code>solve(a)</code> returns <span class="math inline">\(a^{-1}\)</span>. Thus we can calculate <span class="math inline">\(\widehat{\beta}\)</span> using <span class="math inline">\((X^TX)^{-1}X^Ty\)</span>:</p>
<div class="tutorial-exercise-support" data-label="prepare_gala_betahat_calcs" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>X &lt;- model.matrix( ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)
y &lt;- gala$Species
xtxi &lt;- solve(t(X) %*% X)</code></pre>
</div>
<p>Now calculate <span class="math inline">\((X^TX)^{-1}\)</span>:</p>
<div class="tutorial-exercise" data-label="calc_gala_inverse_x_trans_x" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>xtxi &lt;- solve(t(X) %*% X)
xtxi</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"prepare_gala_betahat_calcs","exercise.checker":"NULL"}</script>
</div>
<p>Now we can get <span class="math inline">\(\widehat{\beta}\)</span> directly, using <span class="math inline">\((X^TX)^{-1}X^Ty\)</span>:</p>
<div class="tutorial-exercise" data-label="gala_betahat_calcs" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>betahat &lt;- xtxi %*% t(X) %*% y
betahat</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"prepare_gala_betahat_calcs","exercise.checker":"NULL"}</script>
</div>
<p>Notice that our <code>betahat</code> estimates are <strong>identical</strong> to those returned by the <code>lm()</code> function (scroll back up to compare)!</p>
<div class="under-the-bonnet">
<h3 id="section-under-the-bonnet">Under the bonnet…</h3>
<p>In fact, the <code>lm()</code> function uses a much more robust method of calculating the <span class="math inline">\(\widehat{\beta}\)</span> estimates, called <em>QR decomposition</em>, which is much less sensitive to tiny calculation errors when there is a high degree of collinearity between the predictors (that is, when the matrix is almost singular), and is thus numericlly more stable. In general you should always use the <code>lm()</code> function for this reason, but for “well-behaved” data such as this data set, the results are identical. But mathematically, the QR decomposition is equivalent to the calculations we have performed above.</p>
</div>
<p>There a quite a few other useful quantities contained in the object returned by the <code>lm()</code> function, and even more useful quantities can be found in the object returned by <code>summary()</code> when called on a linear model output object.</p>
<p>We can use the <code>names()</code> function to see the names of all the values stored in the model results object returned by the <code>lm()</code> function, as well as the names of all the values calculated when we use the <code>summary()</code> function on the model results object:</p>
<div class="tutorial-exercise-support" data-label="prepare_gala_linear_model" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmod &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)
lmodsum &lt;- summary(lmod)</code></pre>
</div>
<div class="tutorial-exercise" data-label="lm_object_names" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>names(lmod)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"prepare_gala_linear_model","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise" data-label="summary_of_lm_object_names" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmodsum &lt;- summary(lmod)
names(lmodsum)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"prepare_gala_linear_model","exercise.checker":"NULL"}</script>
</div>
<p>There are also a set of functions that will extract commonly-used quantities from the model object: <code>residuals()</code> extracts the residuals, <code>fitted()</code> returns fitted values (discussed more in the next chapter), <code>df.residual()</code> gives the degrees-of-freedom, <code>deviance()</code> returns the RSS, and <code>coef()</code> gives the <span class="math inline">\(\widehat{\beta}\)</span> estimates.</p>
<p>Thus, we can, for example, obtain an estimate of <span class="math inline">\(\sigma\)</span> for the model:</p>
<div class="tutorial-exercise" data-label="get_sigma_from_summary_of_lm_object" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmodsum$sigma</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"prepare_gala_linear_model","exercise.checker":"NULL"}</script>
</div>
<p>And we can, for example, get the standard errors for the coefficients:</p>
<div class="tutorial-exercise" data-label="get_coefficients_from_summary_of_lm_object" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># examine the coefficients object in the model summary object
lmodsum$coefficients
class(lmodsum$coefficients)

# the standard errors are the second column
lmodsum$coefficients[,2]

# the coef() function on the model object also returns the coefficients
coef(lmod)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"prepare_gala_linear_model","exercise.checker":"NULL"}</script>
</div>
<div id="section-quiz-2" class="section level3">
<h3>Quiz</h3>
<p>Choose which of the following is correct:</p>
<ol style="list-style-type: upper-alpha">
<li>In a linear regression model, the <em>regression co-efficients</em> are denoted <span class="math inline">\(\mathbf{\widehat{\alpha}}\)</span>. The responses or outcomes predicted by the model, also known as the <em>predicted</em> or <em>fitted</em> values, are denoted <span class="math inline">\(\mathbf{\widehat{x}} = \mathbf{X\widehat{\beta}}\)</span>. The difference between the actual outcome (response) and the predicted outcome is called the <em>residual</em> (or the <em>residuals</em>) and is denoted <span class="math inline">\(\widehat{\beta}\)</span>.</li>
<li>In a linear regression model, the <em>regression co-efficients</em> are denoted <span class="math inline">\(\mathbf{\widehat{\epsilon}}\)</span>. The responses or outcomes predicted by the model, also known as the <em>predicted</em> or <em>fitted</em> values, are denoted <span class="math inline">\(\mathbf{\widehat{\beta}} = \mathbf{X\widehat{y}}\)</span>. The difference between the actual outcome (response) and the predicted outcome is called the <em>residual</em> (or the <em>residuals</em>) and is denoted <span class="math inline">\(\widehat{\alpha}\)</span>.</li>
<li>In a linear regression model, the <em>regression co-efficients</em> are denoted <span class="math inline">\(\mathbf{\widehat{\beta}}\)</span>. The responses or outcomes predicted by the model, also known as the <em>predicted</em> or <em>fitted</em> values, are denoted <span class="math inline">\(\mathbf{\widehat{y}} = \mathbf{X\widehat{\beta}}\)</span>. The difference between the actual outcome (response) and the predicted outcome is called the <em>residual</em> (or the <em>residuals</em>) and is denoted <span class="math inline">\(\widehat{\epsilon}\)</span>.</li>
<li>In a linear regression model, the <em>regression co-efficients</em> are denoted <span class="math inline">\(\mathbf{\widehat{\gamma}}\)</span>. The responses or outcomes predicted by the model, also known as the <em>predicted</em> or <em>fitted</em> values, are denoted <span class="math inline">\(\mathbf{\widehat{\epsilon}} = \mathbf{Y\widehat{\beta}}\)</span>. The difference between the actual outcome (response) and the predicted outcome is called the <em>residual</em> (or the <em>residuals</em>) and is denoted <span class="math inline">\(\widehat{\delta}\)</span>.</li>
</ol>
<div class="panel panel-default">
<div data-label="question-3" class="tutorial-question panel-body">
<div id="question-3-answer_container" class="shiny-html-output"></div>
<div id="question-3-message_container" class="shiny-html-output"></div>
<div id="question-3-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
</div>
</div>
<div id="section-gauss-markov-theorem" class="section level2">
<h2>8. Gauss-Markov theorem</h2>
<p>We have seen that the ordinary least squares (OLS) estimator of <span class="math inline">\(\widehat{\beta}\)</span> is plausible, but there are actually several reasons to use it:</p>
<ol style="list-style-type: decimal">
<li>It makes sense geometrically as an orthogonal projection onto the model space.</li>
<li>If the errors are <em>independent and identically (normally) distributed</em>, the OLS estimate of <span class="math inline">\(\widehat{\beta}\)</span> is also the maximum likelihood estimator (we demonstrate this later in this chapter). Recall from the HDAT9200 Statistical Foundations course that the maximum likelihood estimate is the value(s) of a parameter estimate(s), in this case <span class="math inline">\(\beta\)</span>, that maximises the probability of the data that was actually observed.</li>
<li>The Gauss-Markov theorem states that <span class="math inline">\(\widehat{\beta}\)</span> is the best linear unbiased estimate (abbreviated as “BLUE”).</li>
</ol>
<p>We won’t be going through the details of the Gauss-Markov theorem here (those who are interested can find details in section 2.8 of Faraway LMwR). It suffices to know that the theorem shows that the OLS estimate <span class="math inline">\(\widehat{\beta}\)</span> is a good choice, provided that the errors have a normal distribution, are uncorrelated and are of equal variance (that is, that they are <em>i.i.d</em>).</p>
<p>The corollary is that when these conditions do not apply, then we should consider using alternative estimators to fit our model:</p>
<ol style="list-style-type: decimal">
<li>When the errors are correlated or have unequal variance, generalised least squares (GLS) should be used. We will look at GLS estimation in a later chapter of this course.</li>
<li>When the error distribution is not normal, such as when it has a long tail, then robust estimates could be useful - we’ll also briefly cover this in a later chapter of this course, and/or for inference we should use permutation tests and/or bootstrap estimation (we look at this later in this chapter).</li>
<li>When the predictors are highly correlated (that is, they are <em>collinear</em>), then so-called <em>biased estimators</em> such as ridge regression, might be preferable to OLS estimation. We touch on this in a later chapter.</li>
</ol>
<div class="aside">
<h3 id="section-normally-distributed-errors-not-normally-distributed-data">Normally-distributed errors, not normally-distributed data</h3>
<p>Note that the assumption is that the <strong>errors</strong> in the outcome (response) are normally-distributed, conditioned on the predictors <span class="math inline">\(X\)</span>, not that the outcome variable (or the predictor variables) are themselves normally-distributed.</p>
<p>What does that mean? In other words, the distribution of <span class="math inline">\(y\)</span> may be quite non-normal but the assumptions for OLS may still be met, as long as the distribution of the errors for <span class="math inline">\(Y\)</span> are normally distributed. Look at the distribution of the outcome variable in our <code>gala</code> dataset — it is definitely not normal!</p>
<pre class="r"><code>hist(gala$Species, breaks = 15)</code></pre>
<p><img src="lm1_files/figure-html/gala-outcome-hist-1.png" width="100%" /></p>
<p>But that’s OK — the data do not need to be normally distributed — as long as the errors, <span class="math inline">\(\epsilon\)</span>, are normally distributed. We’ll look at better ways of to check that in a later chapter, but we can easily visualise the residuals (errors) like this:</p>
<div class="tutorial-exercise" data-label="visualise_residuals_from_summary_of_lm_object" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># examine the residuals
hist(residuals(lmod), breaks = 15)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"prepare_gala_linear_model","exercise.checker":"NULL"}</script>
</div>
<p>Now, that distribution is not normal, but there are only 30 observations in the dataset, and you can at least see that the distribution is roughly symmetrical, centered around zero, with more density in the middle - quite different to the distribution of the <span class="math inline">\(y\)</span> variable itself, as we saw above. You could convince yourself that if there were more data, then the errors would indeed have a normal distribution with a mean of zero.</p>
</div>
</div>
<div id="section-goodness-of-fit" class="section level2">
<h2>9. Goodness of fit</h2>
<p>So far, we have fitted a linear model to our data, but it would be useful to have a measure or indication of how well it fits the data. The <span class="math inline">\(R^2\)</span> metric, more properly known as the <em>coefficient of determination</em>, or more usefully, the <em>percentage of variance explained</em>, is most commonly used. In the formula below, <em>RSS</em> stands for <em>Residual Sum of Squares</em> and <em>SS</em> for <em>Sum of Squares</em>.</p>
<p><span class="math display">\[
R^2 = 1 - \frac{\sum{(\widehat{y}_i - y_i)^2}}{\sum{(y_i - \bar{y})^2}} = 1 - \frac{\textrm{RSS}}{\textrm{Total SS (Corrected for Mean)}}
\]</span></p>
<p>In words, this equation states that the <span class="math inline">\(R^2\)</span> is one minus the sum of all the squared differences between each value of the outcome variable <span class="math inline">\(y_i\)</span> and each estimate of the outcome variable, <span class="math inline">\(\widehat{y}_i\)</span> as given by our fitted model, divided by the sum of all the squared differences between each value of the outcome variable <span class="math inline">\(y_i\)</span> and the overall mean of <span class="math inline">\(y\)</span>.</p>
<p>The range of <span class="math inline">\(R^2\)</span> is therefore from zero to one — that is, <span class="math inline">\(0 \le R^2 \le 1\)</span> — with values closer to one indicating better fit of the model to the data.</p>
<p>This can be visualised graphically as follows (this example is reproduced from the wikipedia page on the <a href="https://en.wikipedia.org/wiki/Coefficient_of_determination"><em>coefficient of determination</em></a>:</p>
<p><img src="../images/Coefficient_of_Determination.png" /></p>
<p>In the image above, the data points are shown as black dots. On the left, in red, we have the squared residuals with respect to the mean of <em>y</em>, and on the right, we have squared residuals with respect to our model estimates (denoted <em>f</em>). It can be seen that the closer our model fits to the actual data points, the smaller the squared residuals will be, and thus the closer <span class="math inline">\(R^2\)</span> will be to 1.</p>
<p>Note that for a <em>simple</em> linear model with only one predictor, <em>x</em>, then <span class="math inline">\(R^2\)</span> equals the correlation between <em>x</em> and <em>y</em>.</p>
<p>This raises the question: what is a good or an acceptable value for <span class="math inline">\(R^2\)</span>?</p>
<p>The answer really depends on the use of the model. In physics and engineering, where data are often derived from closely controlled experiments and measurements can be precisely taken, <span class="math inline">\(R^2\)</span> values of 0.6 or higher are routinely expected, whereas in health research, social sciences and many areas of biology, an <span class="math inline">\(R^2\)</span> value of 0.6 would be considered good and lower values would still be accepted as an indication of adequate fit.</p>
<p>However, it is a mistake to rely solely on <span class="math inline">\(R^2\)</span> as a measure of goodness-of-fit, or rather, of the adequacy of your model. The following code is taken from the R manual (help) page on <em>anscombe</em>, and refers to <em>Anscombe’s quartet</em>, which is four datasets created by Francis Anscombe, each with the same traditional ststistical properties (Anscombe, Francis J. (1973). Graphs in statistical analysis. The American Statistician, 27, 17–21. doi: 10.2307/2682899.).</p>
<p>Let’s examine the quartet. Each dataset has an <em>x</em> variable (<span class="math inline">\(x_1\)</span> to <span class="math inline">\(x_4\)</span>) and a <em>y</em> varable (<span class="math inline">\(y_1\)</span> to <span class="math inline">\(y_4\)</span>). Here is a summary:</p>
<div class="tutorial-exercise" data-label="anscombes-quartet-summary" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>summary(anscombe)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>Notice that the summary statistics for each of the four datasets suggest that they are all <strong>very</strong> similar to each other.</p>
<p>Now let’s fit a linear model to each dataset. This requires a bit of manipulation of the data due to the way it is stored by default as a built-in dataset in <span class="math inline">\(\textsf{R}\)</span>. Don’t worry too much about the details of this code, although you should be able to work out what it is doing:</p>
<div class="tutorial-exercise" data-label="anscombes-quartet-linear-models" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># define the (simple) regression formula as ff
ff &lt;- y ~ x
# create a list called mods to hold the model results
mods &lt;- setNames(as.list(1:4), paste0(&quot;lm&quot;, 1:4))
# loop over the four datasets in the quartet
for(i in 1:4) {
  # substitute the numbered variable names in the regression formula
  ff[2:3] &lt;- lapply(paste0(c(&quot;y&quot;,&quot;x&quot;), i), as.name)
  ## or   ff[[2]] &lt;- as.name(paste0(&quot;y&quot;, i))
  ##      ff[[3]] &lt;- as.name(paste0(&quot;x&quot;, i))
  # fit the linear model to each of the four datasets,
  # and store results in mods
  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)
  # print out a summary of each model
  cat(paste(&quot;----- Anscombe dataset&quot;,i,&quot;-----&quot;))
  print(summary(lmi))
}</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>If you examine the summary of the model for each of the four datasets, you will see that the <span class="math inline">\(R^2\)</span> and the parameter estimates are all almost identical.</p>
<p>We can make it easier to compare the results — this is a good example of how useful it can be to manipulate regression model results using code.</p>
<div class="tutorial-exercise-support" data-label="anscombes-quartet-linear-models-setup" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># define the (simple) regression formula as ff
ff &lt;- y ~ x
# create a list called mods to hold the model results
mods &lt;- setNames(as.list(1:4), paste0(&quot;lm&quot;, 1:4))
# loop over the four datasets in the quartet
for(i in 1:4) {
  # substitute the numbered variable names in the regression formula
  ff[2:3] &lt;- lapply(paste0(c(&quot;y&quot;,&quot;x&quot;), i), as.name)
  ## or   ff[[2]] &lt;- as.name(paste0(&quot;y&quot;, i))
  ##      ff[[3]] &lt;- as.name(paste0(&quot;x&quot;, i))
  # fit the linear model to each of the four datasets,
  # and store results in mods
  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)
}</code></pre>
</div>
<div class="tutorial-exercise" data-label="anscombes-quartet-linear-models-compare" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>## See how close they are (numerically!)
sapply(mods, coef)
lapply(mods, function(fm) coef(summary(fm)))</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"anscombes-quartet-linear-models-setup","exercise.checker":"NULL"}</script>
</div>
<p>Based on that information, you could be forgiven for thinking that the each model fits each dataset equally well. But you would be wrong! Now let’s look at plots of each of the four datasets in the quartet, with the linear regression models overlaid in blue on each:</p>
<div class="tutorial-exercise" data-label="anscombes-quartet-plots" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>op &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))
for(i in 1:4) {
  ff[2:3] &lt;- lapply(paste0(c(&quot;y&quot;,&quot;x&quot;), i), as.name)
  plot(ff, data = anscombe, col = &quot;red&quot;, pch = 21, bg = &quot;orange&quot;, cex = 1.2,
       xlim = c(3, 19), ylim = c(3, 13))
  abline(mods[[i]], col = &quot;blue&quot;)
}
mtext(&quot;Anscombe&#39;s 4 Regression data sets&quot;, outer = TRUE, cex = 1.5)
par(op)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"anscombes-quartet-linear-models-setup","exercise.checker":"NULL"}</script>
</div>
<p>Oh dear! This underlines the importance of <strong>always</strong> carrying out a thorough <em>exploratory data analysis</em> (EDA) on your data before proceeding to fit regression models. From these plots, it is clear that linear models are only really appropriate for the first (x1) and third (x3) of the four datasets, although there is also clearly an outlier data point in the x3 dataset (we will consider the effect of outliers on regression models in a later chapter).</p>
<p>There are two more key regression modelling concepts which we will touch on in this chapter: <em>identifiabilty</em> and <em>orthogonality</em>.</p>
</div>
<div id="section-identifiabilty" class="section level2">
<h2>10. Identifiabilty</h2>
<p><em>Identifiability</em> is a key concept for regression modelling, and underlines the inescapable truth that it is not possible to fit a statistical model to any and every dataset. Here is the mathematical explanation of why.</p>
<p>We’ve seen that the least squares estimate of <span class="math inline">\(\widehat{\beta}\)</span> is the solution to the <em>normal equations</em>:</p>
<p><span class="math display">\[
X^TX\widehat{\beta} = X^Ty
\]</span> where <span class="math inline">\(X\)</span> is an <span class="math inline">\(n \times p\)</span> matrix of <span class="math inline">\(n\)</span> rows of observations and <span class="math inline">\(p\)</span> columns of predictor variables.</p>
<p>If <span class="math inline">\(X^TX\)</span> is <em>singular</em> and thus cannot be inverted, then there will be an infinite number of solutions to the normal equations, and thus the estimates in <span class="math inline">\(\widehat{\beta}\)</span> are at least partially unidentifiable — that is, they cannot be reliably estimated. <em>Unidentifiability</em> will occur when <span class="math inline">\(X\)</span> is not of <em>full rank</em> — that is, when its columns are linearly dependent (also called <em>collinear</em>).</p>
<p>Here are some examples, taken from <em>LMwR</em>, of how that might arise:</p>
<ol style="list-style-type: decimal">
<li>A person’s height is measured in both centimetres and metres, and both are mistakenly entered as predictor variables into the model. In this case, one variable is just a multiple of the other.</li>
<li>For patients admitted to intensive care units (ICUs) during a stay in hospital, we record the number of days in hospital prior to their admission to ICU, the number of days they stayed in ICU, the number of days in hospital after they left the ICU, and their total length of stay in hospital (including their stay in ICU). There is an exact linear relationship between these four variables (total length of stay in hospital is the sum of the other three variables), and thus if all four of these variables are entered into the model, it will be unidentifiable.</li>
<li>If we have more variables than observations (cases) — that is, if <em>p</em> &gt; <em>n</em>. When <em>p</em> = <em>n</em>, we may be able to estimate all the parameters (<span class="math inline">\(\widehat{\beta}\)</span>), but with no degrees of freedom left to estimate any standard errors or do any hypothesis testing or inference (covered in the next few sections). Such a model, where <em>p</em> = <em>n</em>, is called <em>saturated</em>. When <em>p</em> &gt; <em>n</em>, the model is sometimes called <em>supersaturated</em>. A typical scenario in which this occurs is in bioinformatics, where chips are used to measure the actvity of thousands of genes, but usually only in hundreds of samples (because each chip, which can test just one sample, is quite costly). OLS models are completely unsuitable for such data, and other approaches are required.</li>
</ol>
<p>When dealing with observational data, identifiability problems such as these can often be avoided simply by taking care when constructing models and paying close attention to potential linear dependence of one predictor variable on another. However, sometimes it isn’t obvious!</p>
<p>Identifiability problems often occur in designed experiments, and need to be avoided by imposing constraints as part of the design of the experiment. A detailed discussion of the design of experiments is beyond the scope of these notes.</p>
<p>Unfortunately, different statistical software packages handle nonidentifiability in different ways. When trying to fit unidentifiable regression models, some may raise error messages and refuse to fit the model, while others may still manage to fit a model due to rounding errors in the internal calculations (this is less common these days with the use of 64-bit computers and operating systems, but was common in decades past when 16-bit or 32-bit numeric values were used for calculations, and small numerical errors often accumulated during calculations). In other cases, the statistical software may apply constraints to the data in an attempt to fit a model which would otherwise be nonidentifiable. By default, <span class="math inline">\(\textsf{R}\)</span> fits the largest identifiable model that it can by removing variables in the reverse order in which they appear in the model formula. Let’s look at an example of this behaviour.</p>
<p>Returning to our Galápagos islands dataset, let’s create a new variable called <code>Adiff</code>, which is the difference in area between each island and its nearest neighbouring island, and add that to the linear model we fitted previously:</p>
<div class="tutorial-exercise" data-label="fit-nonidentifiable-model" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>gala$Adiff &lt;- gala$Area - gala$Adjacent
lmodn &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent + Adiff, data=gala)
summary(lmodn)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>If you examine the output of the <code>summary()</code> function carefully, you will see that it has issued a message:</p>
<p><code>Coefficients: (1 not defined because of singularities)</code></p>
<p>and that there is no estimate for the <code>Adiff</code> predictor variable, because <span class="math inline">\(\textsf{R}\)</span> removed it from the model in an attempt to avoid nonidentifiability.</p>
<p>Recall that in Chapter 1 we saw the use of the <code>rankMatrix()</code> function from the <code>Matrix</code> package (which is built-in to <span class="math inline">\(\textsf{R}\)</span>) to calculate the rank of a matrix. Let’s try it with the predictor variables used in the model above:</p>
<div class="tutorial-exercise" data-label="check-rank-nonidentifiable-model" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>gala$Adiff &lt;- gala$Area - gala$Adjacent

# create a matrix of the predictor variables entered into the model
X &lt;- as.matrix(gala[,c(&quot;Area&quot;, &quot;Elevation&quot;, &quot;Nearest&quot;, &quot;Scruz&quot;, &quot;Adjacent&quot;, &quot;Adiff&quot;)])

# find the rank of the matrix
Matrix::rankMatrix(X)[[1]]</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>Note that we have <strong>6</strong> predictor variables in our model, but the rank of the matrix of those predictor variables is only <strong>5</strong>. Thus, the model is not of <em>full rank</em> and hence it is nonidentifiable.</p>
<p>Often, revisiting the your EDA (exploratory data analysis) step which you undertook on the data <strong>before</strong> fitting any models will reveal the likely source(s) of such unidentifiablity. However, there are also systematic ways of searching of for linear combinations between predictor variables - in particular, an <em>eigendecomposition</em> of <span class="math inline">\(X^TX\)</span> will reveal such linear relationships — see section 11.1 of Faraway LMwR for details.</p>
<p>However, you may also encounter mdels which are very close to being nonidentifiable. These can also be problematic, because the parameter (<span class="math inline">\(\widehat{\beta}\)</span>) estimates may be unstable or inaccurate in such circumstances. Let’s simulate that situation with our <code>gala</code> datatset by adding a <strong>very</strong> small uniform random perturbation, at the fourth decimal place, to the <code>Adiff</code> variable which we created above, and then refit the model:</p>
<div class="tutorial-exercise" data-label="fit-nearly-nonidentifiable-model" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># add a very small random amount to the calculation of the Adiff variable to
# give us an Adiffe variable
gala$Adiffe &lt;- (gala$Area - gala$Adjacent) + runif(nrow(gala), -0.0005, 0.0005)
lmodc &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent + Adiffe, data=gala)
summary(lmodc)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>Examine the output — notice that all the parameters are now estimated, and that <span class="math inline">\(\textsf{R}\)</span> has not excluded the <code>Adiffe</code> variable, <strong>but</strong> the standard errors for all the parameters estimates, not just for <code>Adiffe</code>, are now very large. This is because they cannot now be estimated in a stable manner, because the model is very close to nonidentifiability.</p>
<p>In this case, of course, we artificially set up the model to have this problem. We will revisit this problem of <em>collinearity</em> (sometimes also called <em>multicollinearity</em>) in a subsequent chapter.</p>
</div>
<div id="section-orthogonality" class="section level2">
<h2>11. Orthogonality</h2>
<p>Orthogonality is a useful property of data which we might be fitting a model to, because it allows us to interpret the effect of one predictor variable without regard to the other.</p>
<div class="under-the-bonnet">
<h3 id="section-the-mathematics-of-orthogonality">The mathematics of orthogonality</h3>
<p>Suppose we have a dataset which has two predictors, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> and that <span class="math inline">\(X_1^T X_2 = 0\)</span> — that is, they are completely uncorrelated. We can write a regession equation:</p>
<p><span class="math display">\[
Y = X\beta + \epsilon = X_1\beta_1 + X_2\beta_2 + \epsilon
\]</span></p>
<p>and, because <span class="math inline">\(X_1^T X_2 = 0\)</span> (and therefore <span class="math inline">\(X_2^T X_2 = 0\)</span>):</p>
<p><span class="math display">\[
X_TX =
\begin{bmatrix}
X_1^T X_1 &amp; X_1^T X_2 \\
X_2^T X_1 &amp; X_2^T X_2 \\
\end{bmatrix} =
\begin{bmatrix}
X_1^T X_1 &amp; 0 \\
0 &amp; X_2^T X_2 \\
\end{bmatrix}
\]</span></p>
<p>which means (recalling estimation of <span class="math inline">\(\widehat{\beta}\)</span> using the <em>normal equations</em> mentioned above):</p>
<p><span class="math display">\[
\widehat{\beta}_1 = (X_1^TX_1)^{-1}X_1^Ty \qquad \widehat{\beta}_2 = (X_2^TX_2)^{-1}X_2^Ty
\]</span></p>
</div>
<p>What this means is that <span class="math inline">\(\widehat{\beta}_1\)</span> will be the same regardless of whether the other predictor variable <span class="math inline">\(X_2\)</span> is in the model or not, and <em>vice versa</em>. Thus we can interpret the effect of <span class="math inline">\(X_1\)</span> without any regard to <span class="math inline">\(X_2\)</span>. Note however that this decoupling is still not perfect, and very slight changes in the standard errors (SEs) for the <span class="math inline">\(\widehat{\beta}\)</span> estimates may still occur — but the <span class="math inline">\(\widehat{\beta}\)</span> estimates themselves will not change if <span class="math inline">\(X_2\)</span> is in or not in the model.</p>
<p>Unfortunately, perfect orthogonality can only usually be achieved in designed experiments, where it is regarded as a mark of a well-designed experiment. In observational data, as more typically found in health and healthcare settings, some degree of orthogonality between predictor variables is to be hoped for, but perfect orthogonality is usually the exception, not the rule.</p>
</div>
<div id="section-model-inference" class="section level2">
<h2>12. Model inference</h2>
<p>So far we have explored the form of linear models, and how they can be fitted using OLS estimation. In this section we will explore how to make hypothesis tests regarding the model parameters we are estimating, and how to construct confidence intervals around them. These inferential tools are the fundamental building blocks for drawing conclusions about the models you fit, and thus the underlying data to which they are fitted.</p>
<p>An important point here to bear in mind is that if we just wish to estimate the model co-efficients (parameters) <span class="math inline">\(\widehat{\beta}\)</span>, then we don’t have to assume that the errors <span class="math inline">\(\epsilon\)</span> are normally distributed, or that they take any particular distributional form. If we are fitting a model purely for predictive purposes, we might not care about inference on the individual <span class="math inline">\(\beta\)</span> estimates, and the only thing we may care about is how well the model can predict the outcome on unseen data which was not used to fit the model. That is a typical <em>machine learning</em> prediction task, and linear models are perfectly suitable for many such tasks.</p>
<p>However, if we want to estimate confidence intervals around our <span class="math inline">\(\widehat{\beta}\)</span> estimates, or to perform any of the common hypothesis tests, then we <strong>do</strong> need to make this assumption of normally-distributed errors. We will see how we can check this assumption in a later chapter of this course, and we’ll also look at the use of permutation test and bootstrap resampling methods later in this chapter.</p>
<p>If we have used least squares estimation to fit our linear model, then we have already assumed that the errors (residuals) are independently and identically distributed (i.i.d) with a mean of 0 (zero) and variance <span class="math inline">\(\sigma^2\)</span>. This can be expressed as <span class="math inline">\(\epsilon \sim N(0, \sigma^2)\)</span>.</p>
<div id="section-comparing-models-using-hypothesis-tests" class="section level3">
<h3>Comparing models using hypothesis tests</h3>
<p>Given a data set which contains a range of potential predictors, how can we determine which of those predictors should be entered into our model? Consider two models, fitted to the same data set, one a larger model <span class="math inline">\(\Omega\)</span> and the other a smaller model <span class="math inline">\(\omega\)</span>, with fewer predictors.</p>
<p>Intuitively, if both these models fit the data equally well, then we ought to prefer the smaller model <span class="math inline">\(\omega\)</span> over the larger model <span class="math inline">\(\Omega\)</span>, because the additional predictor variables in <span class="math inline">\(\Omega\)</span> would not appear to be adding anything in terms of goodness of fit, and in general in science, simpler explanations are preferred over more complex ones, <a href="https://en.wikipedia.org/wiki/Ceteris_paribus"><em>ceteris paribus</em></a> — that is, <a href="https://en.wikipedia.org/wiki/Occam&#39;s_razor">Occam’s razor</a> usually applies.</p>
<p>However, if the goodness of fit of the larger model <span class="math inline">\(\Omega\)</span> is appreciably better, then we may prefer it, despite its additional complexity. So, let’s take the model <span class="math inline">\(\omega\)</span> as our null hypothesis, and <span class="math inline">\(\Omega\)</span> as an alternative hypothesis.</p>
<p>If the difference between the residual sum of squares for the two models, <span class="math inline">\(\textrm{RSS}_\omega - \textrm{RSS}_\Omega\)</span>, is small, then the fit of the smaller model is almost as good as the fit of the larger model, and we ought to prefer the smaller model on the grounds of simplicity. If the difference <span class="math inline">\(\textrm{RSS}_\omega - \textrm{RSS}_\Omega\)</span> is large, then we ought to prefer the larger model. This suggests that a good test statistic might be something like:</p>
<p><span class="math display">\[ \frac{\textrm{RSS}_\omega - \textrm{RSS}_\Omega}{\textrm{RSS}_\Omega} \]</span> where the denominator <span class="math inline">\(\textrm{RSS}_\Omega\)</span> is used for scaling purposes to allow comparisons using this statistic.</p>
<p>We won’t cover the details here (see p34 of Faraway LMwR if you are interested), but the same statistic can be derived using likelihoods — we’ll cover likelihood ratio tests in a later chapter.</p>
<p>Now, let’s define the number of parameters (number of predictor variables) in model <span class="math inline">\(\Omega\)</span> as <em>p</em>, and the number in model <span class="math inline">\(\omega\)</span> as <em>q</em>, then we can use these to perform some more scaling to yield an <em>F</em>-statistic which has an <em>F</em>-distribution under the null hypothesis:</p>
<p><span class="math display">\[
F =
\frac{(\textrm{RSS}_\omega - \textrm{RSS}_\Omega) / (p - q)}{\textrm{RSS}_\Omega/(n - p)}
\sim F_{p - q, n - p}
\]</span></p>
<p>Details of the derivation of this <em>F</em>-statistic and the <em>F</em>-distribution (also known as <em>Snedecor’s F distribution</em> or the <em>Fisher–Snedecor distribution</em>) may be found in most mathematical statistics texts or in abbreviated form on <a href="https://en.wikipedia.org/wiki/F-distribution">this wikipedia page</a>.</p>
<p>We would reject the null hypothesis if <span class="math inline">\(F &gt; F_{p-q,n-p}^{(\alpha)}\)</span> — that is, if the <em>F</em>-statistic for our model is greater than the quantile of the <em>F</em>-distribution for <span class="math inline">\(p-q,n-p\)</span> degrees of freedom.</p>
<p>Because the degrees of freedom of a model are usually equal to the number of observations minus the number of parameters to be estimated (that is, the number of predictors plus the intercept term), the <em>F</em>-statistic can also be written as:</p>
<p><span class="math display">\[
F =
\frac{(\textrm{RSS}_\omega - \textrm{RSS}_\Omega) / (df_\omega - df_\Omega)}{\textrm{RSS}_\Omega/df_\Omega}
\]</span></p>
<p>where <span class="math inline">\(df_\Omega - n - p\)</span> and <span class="math inline">\(df_\omega = n - q\)</span>, where <span class="math inline">\(n\)</span> is the number of obseravtions in the dataset, and <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> are the number of <span class="math inline">\(\widehat{\beta}\)</span> parameters being estimated in models <span class="math inline">\(\Omega\)</span> and <span class="math inline">\(\omega\)</span> respectively.</p>
<p>This same test statistic applies when the <span class="math inline">\(\omega\)</span> model is a not just a subset of <span class="math inline">\(\Omega\)</span>, but also a subspace.</p>
<div class="aside">
<h3 id="section-what-is-a-subspace">What is a subspace?</h3>
<p>The term <em>subspace</em> here refers to a <a href="https://en.wikipedia.org/wiki/Linear_subspace"><em>linear subspace</em></a>. The mathematical definition of a linear subspace is quite involved, but suffice to say that the linear subspace of a model includes all linear combinations of the parameters in that model. We’ll see an example of model subspace testing below.</p>
</div>
<p>The F-statistic is very widely used in regression modelling and <em>analysis of variance</em> (see below). The nice thing about it is that it is so easy to calculate, since all that is needed is the RSS for the null and alternative hypothesis models (and their degrees of freedom).</p>
</div>
</div>
<div id="section-inference-testing" class="section level2">
<h2>13. Inference testing</h2>
<div id="section-inference-test-on-all-the-predictors" class="section level3">
<h3>Inference test on all the predictors</h3>
<p>The simplest inference test for a linear model is for the question: are any of the predictors useful in predicting the outcome (response)?</p>
<p>Let the full model in question, <span class="math inline">\(\Omega\)</span>, be <span class="math inline">\(y = X\beta + \epsilon\)</span>, where X is a full rank <span class="math inline">\(n \times p\)</span> matrix, and let the reduced model, <span class="math inline">\(\omega\)</span>, the null hypothesis, be just <span class="math inline">\(y = \mu + \epsilon\)</span> where <span class="math inline">\(\mu\)</span> is estimated by <span class="math inline">\(\bar{y}\)</span> - that is, just the mean of <span class="math inline">\(y\)</span>. Thus we can write the model for the null hypothesis as:</p>
<p><span class="math display">\[
H_0 \ : \ \beta_1 = \beta_2 = \ldots \beta_{p -1} = 0
\]</span></p>
<p>In other words, all parameters in the null model except the intercept parameter, <span class="math inline">\(\beta_0\)</span>, are zero.</p>
<p>As we saw earlier:</p>
<p><span class="math display">\[
\textrm{RSS}_\Omega = (y - X\widehat{\beta})^T(y - X\widehat{\beta}) = \widehat{\epsilon}^T\widehat{\epsilon}
\]</span></p>
<p>that is, the residual sum of squares for the full model, and</p>
<p><span class="math display">\[
\textrm{RSS}_\omega = (y - \bar{y})^T(y - \bar{y}) = \textrm{TSS}
\]</span></p>
<p>where <em>TSS</em> stands for <em>total sum of squares corrected for the mean</em>. Thus, the <em>F</em>-statistic is:</p>
<p><span class="math display">\[
F = \frac{(\textrm{TSS - RSS}) / (p  - 1)}{\textrm{RSS} / (n - p)}
\]</span></p>
<p>We then refer to a table of the <em>F</em> distribution for, in this case, <span class="math inline">\(F_{p - 1, n - p}\)</span> degrees of freedom, to obtain a critical value or a <em>p</em>-value. If our <em>F</em>-statistic is larger than our critical value, then we can reject the null hypothesis.</p>
<p>Traditionally, all of this information is presented in an <em>analysis of variance</em> or <em>ANOVA</em> table, as shown below:</p>
<table>
<thead>
<tr class="header">
<th align="left">Source</th>
<th>\</th>
<th align="center">Degrees of Freedom</th>
<th>\</th>
<th align="center">Sum of Squares</th>
<th>\</th>
<th align="center">Mean Square</th>
<th>\</th>
<th align="center"><em>F</em></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Regression</td>
<td>\</td>
<td align="center"><em>p</em> - 1</td>
<td>\</td>
<td align="center"><span class="math inline">\(SS_{reg}\)</span></td>
<td>\</td>
<td align="center"><span class="math inline">\(SS_{reg}/(p - 1)\)</span></td>
<td>\</td>
<td align="center"><em>F</em></td>
</tr>
<tr class="even">
<td align="left">Residual</td>
<td>\</td>
<td align="center"><em>n - p</em></td>
<td>\</td>
<td align="center">RSS</td>
<td>\</td>
<td align="center"><span class="math inline">\(\textrm{RSS} / (n - p)\)</span></td>
<td>\</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td>\</td>
<td align="center"><em>n</em> - 1</td>
<td>\</td>
<td align="center">TSS</td>
<td>\</td>
<td align="center"></td>
<td>\</td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>You will see this sort of output produced by many older statistical packages, such as SPSS or SAS. This layout was originated by <a href="https://en.wikipedia.org/wiki/Ronald_Fisher">R.A. Fisher</a> as a convenient way of laying out all the quantities required to do the arithmetic (by hand) to calculate the <em>F</em>-statistic. Because we now rely on computers to do such calculations, it is a bit of an anachronism and should not be regarded as a requirement when presenting inference results on models.</p>
<p>So what happens if we fail to reject the null hypothesis? Should we definitively conclude that all of our predictors, and hence the model overall, is worthless and that further efforts to fit a useful or meaningful model to our data are fruitless?</p>
<p>No! There are still things which can be tried or investigated, such as whether nonlinear transformation of some of our predictors helps, or whether there are outliers or other anomalies in our data that are obscuring the relationship(s) which we are trying to model. Or there may just not be sufficient data to demonstrate a real effect — which is why we say that we <em>fail to reject</em> the null hypothesis rather than saying that we <em>accept</em> or <em>have proven</em> the null hypothesis. We are always somewhat tentative — this is statistics, after all!</p>
<p>Conversely, if the null hypothesis is rejected by our <em>F</em>-statistic test, it does not imply that our model is the best possible model, or even an adequate model. We don’t know if we need all the predictors that are in the model, or whether a simpler, more parsimonious model would suffice - all we know is that our model is better than the null hypothesis model, which in this case in the intercept-only model using no predictors, just the global mean of <em>y</em>. It may also be that we can improve on our model by adding more predictors, if available, or by transforming existing predictors, or by using them in combinations. Thus, a significant <em>F</em>-statistitic is just the start, not the end, of the modelling process.</p>
<div class="under-the-bonnet">
<h3 id="section-the-f-distribution-in-textsfr">The <em>F</em> distribution in <span class="math inline">\(\textsf{R}\)</span></h3>
<p><span class="math inline">\(\textsf{R}\)</span> includes a family of <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Fdist.html">functions for the <em>F</em> distribution</a> that are along the same lines as those for other statistical distributions, as were encountered in the HDAT9200 Statistical Foundations for Health Data Science course.</p>
<p>Thus we can visualise the <em>F</em>-distribution for a range of degrees of freedom like this:</p>
<div class="tutorial-exercise" data-label="f-dist-viz-1" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="16">
<pre class="text"><code># plot the densities of the F distribution at various degrees=of-freedom
curve(df(x, df1=1, df2=1), from=0, to=2, n=200, col=1, ylab=&quot;F&quot;)
curve(df(x, df1=3, df2=1), from=0, to=2, n=200, col=2, add=TRUE)
curve(df(x, df1=6, df2=1), from=0, to=2, n=200, col=3, add=TRUE)
curve(df(x, df1=3, df2=3), from=0, to=2, n=200, col=4, add=TRUE)
curve(df(x, df1=6, df2=3), from=0, to=2, n=200, col=5, add=TRUE)
curve(df(x, df1=3, df2=6), from=0, to=2, n=200, col=6, add=TRUE)
curve(df(x, df1=6, df2=6), from=0, to=2, n=200, col=7, add=TRUE)

# Add a legend
legend(&quot;topright&quot;, title = &quot;F distributions&quot;,
       c(&quot;df = (1,1)&quot;, &quot;df = (3,1)&quot;, &quot;df = (6,1)&quot;, &quot;df = (3,3)&quot;,
         &quot;df = (6,3)&quot;, &quot;df = (3,6)&quot;, &quot;df = (6,6)&quot;),
       col = c(1, 2, 3, 4, 5, 6, 7), lty = 1)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":8,"fig.height":8,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":"100%","warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>To look up the <em>p</em>-value for a particular value of the <em>F</em> statistic, given particular degrees-of-freedom, we can use the <code>pf()</code> function:</p>
<div class="tutorial-exercise" data-label="f-dist-2" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># F-statistic = 2.5
pf(2.5, df1 = 5, df2 = 12, lower.tail = FALSE)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
</div>
</div>
<div id="section-inference-testing-example" class="section level2">
<h2>14. Inference testing example</h2>
<p>We’ll now revisit the Galápagos Island dataset we used earlier. We’ll fit the same model with the number of species on each island as the outcome (response) variable, and various geographic variables as predictors:</p>
<pre class="r"><code># attach the data from the faraway package
data(gala, package=&quot;faraway&quot;)

# fit the model using the lm() function
lmod &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)</code></pre>
<div class="tutorial-exercise-support" data-label="gala-anova-setup" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>data(gala, package=&quot;faraway&quot;)
lmod &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)
nullmod &lt;- lm(Species ~ 1, data=gala)</code></pre>
</div>
<div id="section-testing-the-overall-model" class="section level3">
<h3>Testing the overall model</h3>
<p>In <span class="math inline">\(\textsf{R}\)</span>, we obtain the test of all predictors versus the null by fitting the null model as well, and then passing both models to the <code>anova()</code> function (check the manual page for <code>anova()</code> by typing <code>?anova</code> at the <span class="math inline">\(\textsf{R}\)</span> console prompt in the usual way). Run the code below and examine the output. Note the use of <code>Species ~ 1</code> to specify the intercept-only null model.</p>
<div class="tutorial-exercise" data-label="gala-anova" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># fit the null model to the same dataset
nullmod &lt;- lm(Species ~ 1, data=gala)

# obtain an ANOVA table by passing the null model and the full model
# to the anova() function
av &lt;- anova(nullmod, lmod)
print(av)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"gala-anova-setup","exercise.checker":"NULL"}</script>
</div>
<p>Note that the <em>p</em>-value for the <em>F</em>-statistic is very small (6.6 x 10<sup>-7</sup>), and thus we can reject the null hypothesis.</p>
<p>Just to cement ideas, let’s do the calculations performed by the <code>anova()</code> function in a step-by-step fashion. Examine the following code, run it, and compared its output to the output of the <code>anova()</code> function, above:</p>
<div class="tutorial-exercise" data-label="gala-anova-step-by-step-1" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="20">
<pre class="text"><code># note use of brackets around the assignment expressions which causes them to print the value
# being assigned (this is just R &quot;syntax sugar&quot;)

# null model RSS
(rss0 &lt;- deviance(nullmod))

# alternate hypothesis model RSS
(rss &lt;- deviance(lmod))

# degrees of freedom of null model
(df0 &lt;- df.residual(nullmod))

# degrees of freedom of alternate hypothesis model
(df &lt;- df.residual(lmod))

# now calculate the F-statistic
(fstat &lt;- ((rss0 - rss) / (df0 - df)) / (rss / df))

# finally look up the p-value for this F-statistic value
pf(fstat, df0 - df, df, lower.tail = FALSE)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"gala-anova-setup","exercise.checker":"NULL"}</script>
</div>
</div>
<div id="section-testing-just-one-predictor" class="section level3">
<h3>Testing just one predictor</h3>
<p>We’ve tested the overall model, and are satisfied that the null hypothesis can be rejected. Now let’s test the effect of just one predictor. In general terms, the null hypothesis for such as test would be <span class="math inline">\(H_0 \ : \ \beta_i = 0\)</span>. With respect to our previous discussion, above, this time <span class="math inline">\(\Omega\)</span> is the model with all <em>p</em> parameters (predictors plus intercept), and <span class="math inline">\(\omega\)</span> is the same model <strong>except</strong> for predictor <em>i</em>.</p>
<p>So let’s try that in practice and test whether the predictor <code>Area</code> can be dropped from the full model by testing the hypothesis that the <span class="math inline">\(\widehat{\beta}_{\textrm{Area}}\)</span> parameter estimate is zero. We just use the same procedure to fit a model without <code>Area</code>, and pass that and the original full model to the <code>anova()</code> function:</p>
<div class="tutorial-exercise" data-label="anova-test-one-variable" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># fit model without Area variable
lmod_sans_area &lt;- lm(Species ~ Elevation + Nearest + Scruz + Adjacent, data=gala)

# show ANOVA results
av2 &lt;- anova(lmod_sans_area, lmod)
print(av2)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"gala-anova-setup","exercise.checker":"NULL"}</script>
</div>
<p>Note the <em>p</em>-value — it indicates that the null hypothesis — that the parameter estimate for <code>Area</code> is zero — <strong>cannot</strong> be rejected here. That is often expressed as something like “the parameter estimate for Area is not significant”. However, we need to bear in mind that this is only respect to the alternative hypothesis model, which is one of many possible models. Thus, we cannot say that <code>Area</code> is definitively a non-significant predictor of the outcome, only that it is non-significant with respect to our (fairly arbitrary) “full” model which incorporates all the geographic variables.</p>
</div>
<div id="section-using-the-t-statistic-as-an-alternative-test" class="section level3">
<h3>Using the <em>t</em>-statistic as an alternative test</h3>
<p>You can also use a <em>t</em>-statistic (against Student’s <em>t</em> distribution as encountered in the HDAT9200 Statistical Foundations course), due to the identity:</p>
<p><span class="math display">\[
t_i = \frac{\widehat{\beta}_i}{se(\widehat{\beta}_i)}
\]</span></p>
<p>We can then check for significance using a <em>t</em>-distribution with <em>n - p</em> degrees of freedom. It can be shown mathematically that <span class="math inline">\(t_i^2\)</span> is equal to the corresponding <em>F</em>-statistics computed using the method we have seen. This is why we see the <em>t</em>-statistic and the <em>p</em>-value for it given by <span class="math inline">\(\textsf{R}\)</span> in the usual regression <code>summary()</code> output. Note that the square of the <em>t</em>-statistic value for <code>Area</code>, and the corresponding <em>p</em>-value, is the same as the <em>F</em>-statistic and the <em>p</em>-value for it which we calculated above using <code>anova()</code>.</p>
<div class="tutorial-exercise" data-label="t-test-same-as-anova" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>summary(lmod)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"gala-anova-setup","exercise.checker":"NULL"}</script>
</div>
<p>For this reason, you generally don’t have to fit null and alternatve hypothesis models and pass them to <code>anova()</code> to assess the statistical significance of each individual predictor — all those calculations are done for you by <span class="math inline">\(\textsf{R}\)</span> when you call the <code>summary()</code> function on a model object. Nice!</p>
</div>
<div id="section-activity" class="section level3">
<h3>Activity</h3>
<p>We noted above that all these parameter estimate significance tests are always with respect to a specific alternate hypothesis. Write some code below to show the summary output for three different models which include the <code>Area</code> variable in the <code>gala</code> dataset: the first model using <code>Species</code> as the outcome, and <code>Area</code>, <code>Elevation</code>, <code>Nearest</code>, <code>Scruz</code> and <code>Adjacent</code> as predictors; the second model the same except only <code>Area</code>, <code>Elevation</code> and <code>Nearest</code> as predictors, and the third model the same except using only <code>Area</code> as a predictor.</p>
<p>What do you notice about the significance of the <code>Area</code> variable in each of these models?</p>
<div class="tutorial-exercise-support" data-label="gala-sig-in-different-models-activity-hint-1" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>summary(lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala))</code></pre>
</div>
<div class="tutorial-exercise-support" data-label="gala-sig-in-different-models-activity-hint-2" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>summary(lm(Species ~ Area + Elevation + Nearest, data=gala))</code></pre>
</div>
<div class="tutorial-exercise-support" data-label="gala-sig-in-different-models-activity-hint-3" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>summary(lm(Species ~ Area, data=gala))</code></pre>
</div>
<div class="tutorial-exercise" data-label="gala-sig-in-different-models-activity" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="5">
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>From this, we can see that we can only say whether a particular predictor is significant or not only in the context of all the other predictors that are in the model, and a variable can easily be non-significant in some models, but significant in others, using the same data, depending on what other variables are also in the model.</p>
<p>At this point you might want to ask “So what is the effect of island area on the number of species?” The answer is that “it depends…”, and there is no simple answer. We’ll explore this more in Chapter 3.</p>
</div>
</div>
<div id="section-testing-pairs-of-predictors" class="section level2">
<h2>15. Testing pairs of predictors</h2>
<p>What if we are interested in whether the area of the island or of the adjacent island has an effect on the number of species? The corresponding null hypothesis for this is: <span class="math inline">\(H_0 \ : \ \beta_{\textrm{Area}} = \beta_{\textrm{Adjacent}} = 0\)</span> given the other three predictors in the model (<code>Elevation</code>, <code>Nearest</code>, <code>Scruz</code>).</p>
<div id="section-activity-1" class="section level3">
<h3>Activity</h3>
<p>Use the usual method, with <code>anova()</code> to test this <span class="math inline">\(H_0\)</span> hypothesis by completing and then running the following code:</p>
<div class="tutorial-exercise-support" data-label="two-vars-test-activity-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmod &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)
lmod_without_area_adjacent &lt;- lm(Species ~ Elevation + Nearest + Scruz, data=gala)
av3 &lt;- anova(lmod_without_area_adjacent, lmod)
print(av3)</code></pre>
</div>
<div class="tutorial-exercise" data-label="two-vars-test-activity" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmod &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)
lmod_without_area_adjacent &lt;-</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"gala-anova-setup","exercise.checker":"NULL"}</script>
</div>
<p>We can reject the null hypothesis because the <em>p</em>-value is small. Thus, it is not reasonable to simplify the model by removing those pair of predictors, <code>Area</code> and <code>Adjacent</code>.</p>
<p>Could we have come to the same conclusion by just examining the significance of these two variables in the “full” model?</p>
<pre><code>## 
## Call:
## lm(formula = Species ~ Area + Elevation + Nearest + Scruz + Adjacent, 
##     data = gala)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -111.679  -34.898   -7.862   33.460  182.584 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  7.068221  19.154198   0.369 0.715351    
## Area        -0.023938   0.022422  -1.068 0.296318    
## Elevation    0.319465   0.053663   5.953 3.82e-06 ***
## Nearest      0.009144   1.054136   0.009 0.993151    
## Scruz       -0.240524   0.215402  -1.117 0.275208    
## Adjacent    -0.074805   0.017700  -4.226 0.000297 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 60.98 on 24 degrees of freedom
## Multiple R-squared:  0.7658, Adjusted R-squared:  0.7171 
## F-statistic:  15.7 on 5 and 24 DF,  p-value: 6.838e-07</code></pre>
<p>Note that the <em>p</em>-values for <code>Area</code> and <code>Adjacent</code> in this model are 0.3 and 0.0003 respectively. Can they be combined in some way to determine the effect of both variables at once? The answer is: <strong>no</strong>. Thus, if you want to test two or more predictors simultaneously, you need to use the <em>F</em>-test as we did above - there’s no short-cut. You can’t (reliably) use the two <em>t</em>-tests instead.</p>
</div>
</div>
<div id="section-testing-subspaces" class="section level2">
<h2>16. Testing subspaces</h2>
<p>We may want to test models that can’t be expressed simply as an inclusion or exclusion of subsets of predictor variables. For example, what if we wanted to test a model that used the sum of the area of the current island (the <code>Area</code> variable) and the area of the adjacent island (the <code>Adjacent</code> variable), in place of each of those variables separately. The null hypothesis for such a test would be:</p>
<p><span class="math display">\[
H_0 \ : \ \beta_{\textrm{Area}} = \beta_{\textrm{Adjacent}}
\]</span></p>
<p>The corresponding model represents a <a href="https://en.wikipedia.org/wiki/Linear_subspace">linear subspace</a> of the full model. We can test this by fitting the null model as shown below, and using the <code>anova()</code> function in the usual way. Note the use of the <code>I()</code> function - this causes evaluation of its argument, which in this case is the addition of the <code>Area</code> and <code>Adjacent</code> values for each row in the dataset, to be performed <strong>before</strong> the data are fitted. This is a convenient short-hand and saves us from having to define a new column called, say, <code>Area_plus_Adjacent</code> in our dataset. Run this code:</p>
<div class="tutorial-exercise" data-label="subspace-testing-1" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmod_area_plus_adj &lt;- lm(Species ~ I(Area + Adjacent) + Elevation + Nearest + Scruz, data=gala)
av4 &lt;- anova(lmod_area_plus_adj, lmod)
print(av4)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"gala-anova-setup","exercise.checker":"NULL"}</script>
</div>
<p>Note that the <em>p</em>-value of 0.028 indicates that the null can be rejected, and thus the simplification of <code>Area</code> and <code>Adjacent</code> into a combined variable containing the sum of <code>Area</code> and <code>Adjacent</code> is not justifiable.</p>
<p>Another type of model subspace test is when we want to test whether a parameter can be set to a particular value. Say we want to test whether <code>Elevation</code> can be set to 0.5, which corresponds to a null hypothesis of:</p>
<p><span class="math display">\[
H_0 \ : \ \beta_{\textrm{Elevation}} = 0.5
\]</span></p>
<p>We do this using an <em>offset</em>, which is implemented in <span class="math inline">\(\textsf{R}\)</span> using the <code>offset()</code> function. Run this code which compares such an offset model to the full model:</p>
<div class="tutorial-exercise" data-label="subspace-testing-2" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmod_offset_elev_0.5 &lt;- lm(Species ~ Area + offset(0.5*Elevation) + Nearest + Scruz + Adjacent, data=gala)
av5 &lt;- anova(lmod_offset_elev_0.5, lmod)
print(av5)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"gala-anova-setup","exercise.checker":"NULL"}</script>
</div>
<p>Note that the <em>p</em>-value is small and the null hypothesis is rejected.</p>
<div class="aside">
<p>There’s a simpler way to test such point hypotheses, using a <em>t</em>-statistic:</p>
<p><span class="math display">\[
t = \frac{\widehat{\beta} - c}{\textrm{se}(\widehat{\beta})}
\]</span></p>
<p>where <em>c</em> is the point hypothesis. Thus, referring back to the <code>summary()</code> output for the full model, the <em>t</em>-statistic and corresponding <em>p</em>-value are:</p>
<pre class="r"><code>(tstat &lt;- (0.31946 - 0.5) / 0.05366)</code></pre>
<pre><code>## [1] -3.364517</code></pre>
<pre class="r"><code># p-value
2*pt(tstat, 24)</code></pre>
<pre><code>## [1] 0.002572168</code></pre>
<pre class="r"><code># square of the t-statistic is the F-statistic
tstat^2</code></pre>
<pre><code>## [1] 11.31998</code></pre>
<p>Compare these values with those that appear in the ANOVA table above — they are the same.</p>
</div>
<div id="section-limitations-of-the-f-test" class="section level3">
<h3>Limitations of the <em>F</em>-test</h3>
<p>We can’t use <em>F</em>-testing for non-linear hypotheses such as <span class="math inline">\(H_0 \ : \ \beta_j\beta_k = 1\)</span> — that requires a non-linear model, which is beyond the scope of this course.</p>
<p>Nor can models that are not nested be compared. For example, if one model is fitted using <code>Area</code>, <code>Adjacent</code> and <code>Scruz</code>, while another model uses <code>Area</code> and <code>Elevation</code>, then an <em>F</em>-test cannot be used to compare them. There are methods for deciding which of such non-nested models is preferable, which we will cover in Chapter 4 of this course.</p>
<p>Another limitation is when the models we compare use different datasets. This may occur in a non-obvious way: for example, different sets of predictor variables may have different patterns of missing values, and rows with missing values in the predictor variables (or the outcome) are not (and cannot be) used when fitting a model. Thus, there may be different subsets of rows of our data used when fitting models with different sets of predictors, even though the same underlying dataset has been specified. Solutions to this involve filling in the missing values, a process called imputation, which we will also look at briefly in Chapter 4.</p>
</div>
</div>
<div id="section-permutation-tests" class="section level2">
<h2>17. Permutation tests</h2>
<p>All of the inferential test we have carried out so far rest on the assumption of normal errors. Due to the Central Limit Theorem, we can convincingly argue that the errors are likely to be normal, or close to normal, provided that the dataset is large enough (has enough observations). The problem is that there is no easy way to decide exactly how large is large enough, although it is easy to decide how small is too small, and a general rule of thumb is that in any dataset with less than 30 observations, the assumption of normality of the errors needs to be viewed with some scepticism. However, permutation tests offer an alternative that does not assume normality of the model errors.</p>
<p>The intuitive rationale for permutation tests is as follows. Considering our Galápagos Islands dataset, suppose that the outcome variable — the number of species on each island — actually had no relationship to the five geographical variables that we have been using as predictors. If that were the case, then the observed outcome (number of species) would be randomly distributed amongst the islands, with no relation to the predictors. However, as we saw in above in the discussion of the rationale for the <em>F</em>-statistic, the <em>F</em>-statistic is a good measure of the association between predictors and the outcome, and larger values of the <em>F</em>-statistic indicates a stronger association between a predictor (or subset or subspace of predictors) and the outcome.</p>
<p>Given that, we can pose the question: what would be the probability that that an <em>F</em>-statistic would be observed as large or larger than the one we have observed. If we compute the <em>F</em>-statistic for all possible permutations of the outcome variable (there are <em>n</em> factorial, <span class="math inline">\(n!\)</span>, such permutations), we can determine what proportion exceeds the observed <em>F</em>-statistic, and thus estimate that probability. This constitutes a permutation test. By “all possible permutations of the outcome variable”, we mean all random orderings of it. The <code>sample()</code> function in <span class="math inline">\(\textsf{R}\)</span>, when called without additional arguments, conveniently returns such a random permutation of whatever vector is passed to it.</p>
<p>If the observed proportion is small, then we can reject the hypothesis that the outcome is unrelated to the predictors.</p>
<p>Of course, with large datasets, fitting models to every possible permutation of the outcome variable is computationally infeasible — even with just 30 observations, there are 2.652528610^{32} possible permutations — but it is possible to just use a random sample of all possible permutations. Let’s try that now with the <code>gala</code> dataset.</p>
<p>First, let’s fit a model using just <code>Nearest</code> and <code>Scruz</code> as predictors in order to get a <em>p</em>-value for the overal model <em>F</em>-statistic that isn’t too small. Run this code:</p>
<div class="tutorial-exercise-support" data-label="gala-perm-test-set-up" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>nreps &lt;- 4000
lmod2 &lt;- lm(Species ~ Nearest + Scruz, data=gala)
lmod2summary &lt;- summary(lmod2)</code></pre>
</div>
<div class="tutorial-exercise" data-label="gala-perm-test-1" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmod2 &lt;- lm(Species ~ Nearest + Scruz, data=gala)
(lmod2summary &lt;- summary(lmod2))</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>We can get the <em>F</em>-statistic details (as shown in the final line of the output above) from the model summary object and calculate the <em>p</em>-value for it like this:</p>
<div class="tutorial-exercise" data-label="gala-perm-test-2" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># get the F-statistic value and degrees of freedom
lmod2summary$fstatistic

# pass those value to the pf() function to find the corresponding p-value
pf(lmod2summary$fstatistic[1], lmod2summary$fstatistic[2], lmod2summary$fstatistic[3], lower.tail = FALSE)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"gala-perm-test-set-up","exercise.checker":"NULL"}</script>
</div>
<p>Now let’s generate 4000 random permutations of outcome variable <code>Species</code>, and fit a model to each of those permutations, and calculate the <em>F</em>-statistic for each permuatation and store it in a vector. We then determine what proportion of the <em>F</em>-statistic values from those 4000 permutations are greater than the <em>F</em>-statistic for the model we fitted to the actual (unpermuted) data, above. Examine the code below and make sure that you understand what it is doing before you run it. It may take some time to run, depending on the speed of your computer.</p>
<div class="tutorial-exercise" data-label="gala-perm-test-3" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="21">
<pre class="text"><code># define the number of replications
nreps &lt;- 4000

# set a seed so it is reproducible
set.seed(123)

# create an empty numeric vector to store the results
fstats &lt;- numeric(nreps)

# now loop for nreps times (4000 in this case)
for(i in seq(nreps)) {
  # fit a model to a permutation of the outcome variable
  permutation_lmod2 &lt;- lm(sample(Species) ~ Nearest + Scruz, data=gala)
  # store the F-statistic from that model in the results vector
  fstats[i] &lt;- summary(permutation_lmod2)$fstatistic[1]
}

# now calculate the proportion of those permutation F-statistics that are
# greater than the F-statistics for the unpermuted data
mean(fstats &gt; lmod2summary$fstatistic[1])</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.timelimit":360,"exercise.setup":"gala-perm-test-set-up","exercise.checker":"NULL"}</script>
</div>
<p>Notice how close the permutation-based <em>p</em>-value is to the normal theory-based _p-value: 0.56 versus 0.55 respectively. This shows that the normal theory <em>p</em>-values are quite robust, even in datasets with just 30 observations, but if there were a larger difference, we would prefer the permutation-based test statistic because it is <strong>very</strong> robust to non-normality in the errors.</p>
<p>We can also use permutation to test just one predictor — the approach is similar but we permute the values of just the predictor of interest, rather than the outcome variable. Let’s test the <code>Scruz</code> variable in the model we fitted above. Instead of extracting the <em>F</em>-statistic for the entire model from the model object, we extract the <em>t</em>-statistic for just the predictor variable of interest:</p>
<div class="tutorial-exercise" data-label="gala-perm-test-4" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># note that the t-statistic is in cell [3,3] of this matrix
summary(lmod2)$coefficients</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"gala-perm-test-set-up","exercise.checker":"NULL"}</script>
</div>
<p>Then we perform 4000 permutations of the <code>Scruz</code> variable, fit a model to these permutations, and see what proportion of the <em>t</em>-test statistics exceed the <em>t</em>-test statistic we observed for the <code>Scruz</code> variable in the unpermuted data (as shown above). Again, this may take some time to run — so be patient!</p>
<div class="tutorial-exercise" data-label="gala-perm-test-5" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>tstats &lt;- numeric(nreps)
set.seed(123)
for(i in seq(nreps)) {
   permutation_lmod2 &lt;- lm(Species ~ Nearest + sample(Scruz), data=gala)
  # store the t-statistic from that model in the results vector
  tstats[i] &lt;- summary(permutation_lmod2)$coefficients[3,3]
}

mean(abs(tstats) &gt; abs(lmod2summary$coefficients[3,3]))</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.timelimit":360,"exercise.setup":"gala-perm-test-set-up","exercise.checker":"NULL"}</script>
</div>
<p>Notice again how close the permutation test <em>p</em>-value is to the normal theory-based <em>p</em>-value for the <code>Scruz</code> variable in this model: 0.27 versus 0.28, respectively. Again, if these results disagreed, and we had any reason to doubt the normality of the errors (such as if the dataset were small, as it is in this case), then we would prefer the permuatation test <em>p</em>-value.</p>
<div id="section-activity-2" class="section level3">
<h3>Activity</h3>
<p>Write some code, to perform a permutation test for the <code>Nearest</code> variable instead. You can just re-use the code above and adapt it as required:</p>
<div class="tutorial-exercise-support" data-label="gala-perm-test-6-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>tstats &lt;- numeric(nreps)
set.seed(123)
for(i in seq(nreps)) {
   permutation_lmod2 &lt;- lm(Species ~ sample(Nearest) + Scruz, data=gala)
  # store the t-statistic from that model in the results vector
  tstats[i] &lt;- summary(permutation_lmod2)$coefficients[2,3]
}

mean(abs(tstats) &gt; abs(lmod2summary$coefficients[2,3]))</code></pre>
</div>
<div class="tutorial-exercise" data-label="gala-perm-test-6" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="14">
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.timelimit":360,"exercise.setup":"gala-perm-test-set-up","exercise.checker":"NULL"}</script>
</div>
<p>Of course, there are <span class="math inline">\(\textsf{R}\)</span> packages that automate such permutation tests for us, in particular the <a href="https://cran.r-project.org/web/packages/coin/vignettes/coin.pdf"><em>coin</em> package</a> and the <a href="https://cran.r-project.org/web/packages/lmPerm/vignettes/lmPerm.pdf"><em>lmPerm</em> package</a>. We won’t go into the details of these packages here, but they make it easy to use permutation tests (with small datasets, of course).</p>
</div>
</div>
<div id="section-confidence-intervals-for-beta" class="section level2">
<h2>18. Confidence intervals for <span class="math inline">\(\beta\)</span></h2>
<p>As mentioned in The HDAT9200 Statistical Foundations course, in general, confidence intervals (CIs) are preferred to <em>p</em>-values for most purposes, and this applies to <span class="math inline">\(\widehat{\beta}\)</span> estimates as well. Confidence limits for <span class="math inline">\(\widehat{\beta}_i\)</span> can be calculated as:</p>
<p><span class="math display">\[
\widehat{\beta}_i \pm t_{(n-p)}^{(\alpha/2)}  \textrm{se}(\widehat{\beta}_i)
\]</span></p>
<p>That’s not as complex as it might seem - it just means that the upper and lower confidence intervals are the <span class="math inline">\(\widehat{\beta}\)</span> estimate values plus or minus the quantile of the <em>t</em> distribution for (<em>n - p</em>) degrees of freedom, times the standard error of the <span class="math inline">\(\widehat{\beta}\)</span> estimate. Let’s work through those calculations for our “full” model on the Galápagos Island data. Here is the full model again:</p>
<div class="tutorial-exercise-support" data-label="conf-ints-set-up" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>lmod &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)</code></pre>
</div>
<pre class="r"><code>lmod &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)
summary(lmod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Species ~ Area + Elevation + Nearest + Scruz + Adjacent, 
##     data = gala)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -111.679  -34.898   -7.862   33.460  182.584 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  7.068221  19.154198   0.369 0.715351    
## Area        -0.023938   0.022422  -1.068 0.296318    
## Elevation    0.319465   0.053663   5.953 3.82e-06 ***
## Nearest      0.009144   1.054136   0.009 0.993151    
## Scruz       -0.240524   0.215402  -1.117 0.275208    
## Adjacent    -0.074805   0.017700  -4.226 0.000297 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 60.98 on 24 degrees of freedom
## Multiple R-squared:  0.7658, Adjusted R-squared:  0.7171 
## F-statistic:  15.7 on 5 and 24 DF,  p-value: 6.838e-07</code></pre>
<p>So, to construct 95% CIs for, say, <span class="math inline">\(\beta_{\textrm{Area}}\)</span>, we need the 2.5% and 97.5% percentiles of the <em>t</em>-distribution for 30 rows - 6 parameters = 24 degrees of freedom:</p>
<pre class="r"><code>qt(0.975, 30 - 6)</code></pre>
<pre><code>## [1] 2.063899</code></pre>
<p>and we use that and the <span class="math inline">\(\beta\)</span> estimate and its standard error from the model summary output table above:</p>
<pre class="r"><code># note the trick here of using a c(-1, 1) vector to
# calculate both lower and upper CIs at once, thanks to
# vectorised arithmetic in R

-0.02394 + c(-1, 1) * 2.0639 * 0.02242</code></pre>
<pre><code>## [1] -0.07021264  0.02233264</code></pre>
<p>Notice that this confidence interval contains zero — this indicates that the null hypothesis <span class="math inline">\(H_0 \ : \ \beta_{\textrm{Area}} = 0\)</span> would not be rejected at the 5% level. This is consistent with the <em>p</em>-value for the <code>Area</code> predictor in the model summary table of 0.296 (that is, 29.6%, which is greater than 5%).</p>
<p>Likewise we can calculate the CIs for <span class="math inline">\(\beta_{\textrm{Adjacent}}\)</span>:</p>
<pre class="r"><code>-0.07480 + c(-1, 1) * 2.0639 * 0.01770</code></pre>
<pre><code>## [1] -0.11133103 -0.03826897</code></pre>
<p>This interval does not include zero, and thus the null hypothesis can be rejected.</p>
<p>Of course, <span class="math inline">\(\textsf{R}\)</span> provides a convenient way to obtain all the univariate parameter estimate CIs for a model by using the <code>confint()</code> function (see its <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/confint.html">manual page</a> for details):</p>
<div class="tutorial-exercise" data-label="conf-ints-5" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>confint(lmod)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"conf-ints-set-up","exercise.checker":"NULL"}</script>
</div>
<p>Confidence intervals tend to be more informative that just hypothesis test <em>p</em>-values because they give some information about the plausible ranges for the parameters, which is particularly useful when the parameters have a direct interpretation (which we will discuss in the next chapter).</p>
<p>Confidence intervals also help avoid the temptation to read too much into the size of <em>p</em>-values, in particular the tendency to interpret small <em>p</em>-values as indicating that a variable has particular practical importance, as opposed to just being statistically significant. In health care research settings, it is often (correctly!) said that “statistical significant does not equal clinical significance”. Confidence intervals are better in this regard because they provide information about the size of an effect, not just its statistical significance.</p>
<div id="section-cis-for-more-than-one-parameter" class="section level3">
<h3>CIs for more than one parameter</h3>
<p>It is possible to construct a 100(1 - <span class="math inline">\(\alpha\)</span>)% confidence region for <span class="math inline">\(\beta\)</span> (that is, for all the parameter estimates at once). Such regions are an ellipse when there are two parameters, and egg-shaped solid when there are three parameters, and ellipsoids in higher dimensions (which are very hard to visualise) when there are more than three parameters. The <em>ellipse</em> package in <span class="math inline">\(\textsf{R}\)</span> conveniently does the calculations for us. Let’s construct the joint 95% confidence region for <span class="math inline">\(\beta_{\textrm{Area}}\)</span> and <span class="math inline">\(\beta_{\textrm{Adjacent}}\)</span>:</p>
<div class="tutorial-exercise" data-label="conf-ints-6" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># Area and Adjacent are the 2nd and 6th parameters in the model
plot(ellipse::ellipse(lmod, c(2, 6)), type=&#39;l&#39;, ylim=c(-0.13, 0))

# add a dot at the point of the best estimates for the two predictors
points(coef(lmod)[2], coef(lmod)[6], pch=19)

# add dotted lines for the univariate confidence limits in two dimensions
abline(v = confint(lmod)[2,], lty=2)
abline(h = confint(lmod)[6,], lty=2)

# mark a point for discussion
text(0.0236, -0.0363, &quot;o&quot;)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":8,"fig.height":8,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":"100%","warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"conf-ints-set-up","exercise.checker":"NULL"}</script>
</div>
<p>We can test various hypotheses using this plot. The joint null hypothesis <span class="math inline">\(H_0 \ : \ \beta_{\textrm{Area}} = \beta_{\textrm{Adjacent}} = 0\)</span> can be rejected because the origin (0, 0) does not lie inside the ellipse.</p>
<p>However, the hypothesis <span class="math inline">\(H_0 \ : \ \beta_{\textrm{Area}} = 0\)</span> cannot be rejected because zero lies inside the vertical dashed lines representing the univariate CIs for <code>Area</code>. Conversely, zero does not lie between the horizontal dashed lines representing the CIs for <code>Adjacent</code>, and thus <span class="math inline">\(H_0 \ : \ \beta_{\textrm{Adjacent}} = 0\)</span> can be rejected.</p>
<p>All these findings agree with the <em>p</em>-values in the summary table for our model, above. But imagine a model in which origin fell at point ‘o’ on the plot. Then both univariate CIs would not include zero, and the null hypotheses could be rejected on that basis, but the origin 0,0 would lie inside the ellipse, and thus the null hypothesis could <strong>not</strong> be rejected for the joint CIs. Which would be correct? The joint CIs, as represented by the ellipse! In other words, if you want to test multiple parameters for joint statistical significance, then you need to use a joint testing procedure — it is not enough to try to combine univariate CIs into higher dimensions.</p>
</div>
</div>
<div id="section-bootstrap-cis" class="section level2">
<h2>19. Bootstrap CIs</h2>
<p>The <em>F</em>-statistic and <em>t</em>-statistic based confidence intervals and regions we have seen so far all rely on the assumption of normality of the errors. The <em>bootstrap</em> provides us with a way of constructing confidence intervals without relying on that assumption. By <em>bootstrap</em> we mean, of course, <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">Efron’s <em>bootstrap</em></a>, as encountered in the HDAT9200 Statistical Foundations course.</p>
<p>These are the steps involved:</p>
<ol style="list-style-type: decimal">
<li>Generate <span class="math inline">\(\epsilon^*\)</span> by sampling with replacement from <span class="math inline">\(\widehat{\epsilon}_1, \ldots, \widehat{\epsilon}_n\)</span></li>
<li>Form <span class="math inline">\(y^* = X\widehat{\beta} + \epsilon^*\)</span></li>
<li>Compute <span class="math inline">\(\widehat{\beta}^*\)</span> from <span class="math inline">\((X, y^*)\)</span></li>
</ol>
<p>To implement this, we just use the <code>sample()</code> function to generate random samples of row indices which we use to draw samples from our original data:</p>
<pre class="r"><code>sample(10, replace=TRUE)</code></pre>
<pre><code>##  [1]  1  8  9 10  2  7  3 10  9 10</code></pre>
<p>Let’s use that to calculate bootstrap CIs for our “full” model, using 4000 samples. Be sure that you understand what the following code does (the comments should help) before you run it. Note that <code>resids</code> in the code below are the <span class="math inline">\(\epsilon\)</span> in the steps above, and thus <code>sample(resids, replace=TRUE)</code> are <span class="math inline">\(\epsilon^*\)</span>. Likewise, <code>preds</code> in the code below are the <span class="math inline">\(X\beta\)</span> term in step 2 above (the <code>fitted()</code> function calculates these for us from the model object). Note also the use of the <code>update()</code> function, which updates and re-fits an existing model — see the <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/update.html">manual page</a> for it for details. The formula <code>y_star ~ .</code> in the <code>update()</code> call means “replace the outcome column with <code>y_star</code> but keep everything else the same as in the original model that produced the <code>lmod</code> model object”.</p>
<div class="tutorial-exercise" data-label="bootstrap-ci-2" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="42">
<pre class="text"><code># set PRNG seed for reproducibility
set.seed(123)

# fit the &quot;full&quot; model with original data
lmod &lt;- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data=gala)

# number of replicates (samples with replacement)
nb &lt;- 4000

# make a matrix filled initially with NAs, with 6 columns to hold
# the fitted coefficients for each of 4000 bootstrapped replicates
coefmat &lt;- matrix(NA, nrow=nb, ncol=6)

# get the residuals for the model fitted to the original data
resids &lt;- residuals(lmod)

# get the predicted values
preds &lt;- fitted(lmod)

# loop 4000 times
for (i in seq(nb)) {
  # create y*
  y_star &lt;- preds + sample(resids, replace=TRUE)
  # refit the model using y_star instead of y
  bmod &lt;- update(lmod, y_star ~ .)
  # store the vector of coefficients for the ith bootstrap replicate
  # in the matrix we pre-defined
  coefmat[i,] &lt;- coefficients(bmod)
}

# add some column names to the matrix to make it more readable
colnames(coefmat) &lt;- c(&quot;(Intercept)&quot;, colnames(gala[,3:7]))

# convert the matrix into a data frame
# we only do this becase we are going to use the ggplot2 package
# to draw a plot, and it requires data to be in data frames
coefdf &lt;- data.frame(coefmat)

# calculate the 2.5% and 97.5% quantiles for each column in the data frame
bootstrap_cis &lt;- apply(coefdf, 2, function(x) quantile(x, c(0.025, 0.975)))
# print the resulting two row matrix as two columns, using the transpose function
t(bootstrap_cis)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.timelimit":360,"exercise.setup":"conf-ints-set-up","exercise.checker":"NULL"}</script>
</div>
<p>Compare these bootstrap CIs with those returned by the <code>confint()</code> function, based on the assumption of normality of the errors:</p>
<div class="tutorial-exercise" data-label="bootstrap-ci-3" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>confint(lmod)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"conf-ints-set-up","exercise.checker":"NULL"}</script>
</div>
<p>Notice that the confidence intervals are not identical, but are nonetheless comparable between the two methods. The differences would be smaller if the dataset were larger and/or more replicates were used.</p>
<div class="aside">
<h3 id="section-libraries-for-bootstrapped-cis">Libraries for bootstrapped CIs</h3>
<p>Of course, there are several excellent packages available for <span class="math inline">\(\textsf{r}\)</span> which make the calculation of bootstrapped confidence intervals easier. Here’s an illustration of the use of the <code>Boot()</code> function in the <a href="https://cran.r-project.org/web/packages/car/index.html"><em>car</em></a> library, which is itself an easier-to-use wrapper around the <code>boot()</code> function in the <a href="https://cran.r-project.org/web/packages/boot/index.html"><em>boot</em></a> package:</p>
<div class="tutorial-exercise" data-label="bootstrap-ci-4" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># load the car package which contains the Boot() function
library(car)

# now just pass the Boot() function our model object, with a vector of labels for
# each of the parameter estimates
labels &lt;- c(&quot;(Intercept)&quot;, &quot;Area&quot;, &quot;Elevation&quot;, &quot;Nearest&quot;, &quot;Scruz&quot;, &quot;Adjacent&quot;)
bootstrapped_lmod &lt;- Boot(lmod, labels=labels)
# now called the Confint() function (note leading cap) on our bootstrapped model object
Confint(bootstrapped_lmod)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":false,"error":false,"message":false,"exercise.df_print":"paged","exercise.setup":"conf-ints-set-up","exercise.checker":"NULL"}</script>
</div>
<p>Scroll back up and compare these confidence intervals with those obtained by our own bootstrap calculations and the parametric, normal theory-based CIs.</p>
<p>One advantage of using packages such as <em>boot</em> and <em>car</em> is that the bootstrapping functions they contain can every easily take advantage of parallel processing, in which parts of the bootstrapping task are distributed to multiple CPU cores on your computer, or even to multiple computers in a large high performance computing (HPC) compute cluster, so that multiple parts of the necessary resampling and model refitting can all run at the same time, leading to faster results. This is important when using bootstrapping on larger datasets, because the bootstrap and similar resampling methods are intrinsically computationally-intensive.</p>
</div>
</div>
<div id="section-fitting-via-mle" class="section level2">
<h2>20. Fitting via MLE</h2>
<p>You will recall from the chapter on Likelihood in the HDAT9200 Statistical Foundations of Health Data Science course that it is also possible to use a technique known as Maximum Likelihood Estimation (MLE) to find parameter estimates which maximise a likelihood or log-likelihood function - in other words, to find parameter estimates that maximise the probability of observing the data. MLE is most often used to fit non-linear models, and/or models in which the errors are not normally distributed. However, it can be used to fit linear models for which OLS fitting would typically be used. Let’s look at how MLE can be used to fit our “full” model to the Galápagos islands data.</p>
<div class="tutorial-exercise" data-label="mle-lm-fit-1" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="35">
<pre class="text"><code># load the bbmle library which contains the mle2() function we will use
library(bbmle)

# define an objective function with arguments for each of the parameters to be optimised by MLE
linregfun &lt;- function(Intercept, Beta_Area, Beta_Elevation, Beta_Nearest, Beta_Scruz, Beta_Adjacent, sigma) {
  # assign columns in our dataset to vectors just for clarity
   y &lt;- gala$Species
  x1 &lt;- gala$Area
  x2 &lt;- gala$Elevation
  x3 &lt;- gala$Nearest
  x4 &lt;- gala$Scruz
  x5 &lt;- gala$Adjacent
  # calculate the deterministic part of the model - Y.pred is just the predicted outcome for each
  # observation in our dataset
  Y.pred &lt;- Intercept + Beta_Area*x1 + Beta_Elevation*x2 + Beta_Nearest*x3 + Beta_Scruz*x4 + Beta_Adjacent*x5
  # calculate the negative log likelihood for the residuals. This just returns the negative sum of the
  # probability of observing the residual that we get, for each observation in our dataset, assuming a
  # normal distribution
  neg_log_likelihood &lt;- -sum(dnorm(y, mean = Y.pred, sd = sigma, log = TRUE))
  return(neg_log_likelihood)
}

# call mle2() with a set of starting values for our parameter estimates which are to be optimised
# by minimising the negative log likelihood returned by the lineregfun() we defined above
mle2.model &lt;- mle2(linregfun,
                   start = list(Intercept = 14, Beta_Area = 0, Beta_Elevation=0,
                                Beta_Nearest=0, Beta_Scruz=0, Beta_Adjacent=0, sigma = 1))

# examine the resulting model fitted by MLE
summary(mle2.model)

# compare it to the model fitted by OLS
summary(lmod)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.setup":"conf-ints-set-up","exercise.checker":"NULL"}</script>
</div>
<p>Notice that the parameter estimates and standard errors for the MLE-fitted model and the OLS-fitted model are similar, although not identical. With a larger dataset, they would be very close.</p>
</div>
<div id="section-in-the-next-chapter" class="section level2">
<h2>21. In the next chapter…</h2>
<p>Congratulations on working through this chapter! It covers a lot of material, but by now you should have a good idea of what linear statistical models are, how they are fitted to the data, how statistical inference can be performed on the estimated parameters, some of the assumptions on which the fitting and estimation methods rely, and alternative methods that enable some of those assumptions to be relaxed or worked-around. Phew!</p>
In the next chapter we’ll briefly look at the interpretation of linear models, how linear models can be used for prediction as well as explanation, and then we’ll delve into model diagnostics and more checking of model assumptions. 
<script type="application/shiny-prerendered" data-context="server-start">
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
data(gala, package="faraway")
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = list(id = "au.edu.unsw.cbdrh.hdat9600.tutorials.lm1"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::session_stop_event(session)
      })
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "question-1", question = structure("Choose the correct statement:", html = TRUE, class = c("html", "character")), answers = list(structure(list(id = "lnr_ans_a557a84",     option = "Describing a regression model as _multivariate_ means that it has two or more outcome variables.",     value = "Describing a regression model as _multivariate_ means that it has two or more outcome variables.",     label = structure("Describing a regression model as <em>multivariate<\u002fem> means that it has two or more outcome variables.", html = TRUE, class = c("html",     "character")), correct = FALSE, message = structure("A <em>multivariable<\u002fem> model has two or more outcome variables, whereas a <em>multivariate<\u002fem> model has two or more explanatory or predictor variables.", html = TRUE, class = c("html",     "character"))), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_f1af61d", option = "In a linear regression model, both the outcome (response) and explanatory (predictor) variables must be continuous quantities.",     value = "In a linear regression model, both the outcome (response) and explanatory (predictor) variables must be continuous quantities.",     label = structure("In a linear regression model, both the outcome (response) and explanatory (predictor) variables must be continuous quantities.", html = TRUE, class = c("html",     "character")), correct = FALSE, message = structure("No, in a linear regression model, only the outcome (response) variable must be continuous.", html = TRUE, class = c("html",     "character"))), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_cfd6058", option = "In a regression model, the response or outcome variable is denoted $Y$, and the explanatory or predictor variables are always denoted $X_1, ..., X_p$",     value = "In a regression model, the response or outcome variable is denoted $Y$, and the explanatory or predictor variables are always denoted $X_1, ..., X_p$",     label = structure("In a regression model, the response or outcome variable is denoted \\(Y\\), and the explanatory or predictor variables are always denoted \\(X_1, ..., X_p\\)", html = TRUE, class = c("html",     "character")), correct = TRUE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer"))), button_labels = list(submit = structure("Submit Answer", html = TRUE, class = c("html", "character")), try_again = structure("Try Again", html = TRUE, class = c("html", "character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", "character")), try_again = structure("Incorrect", html = TRUE, class = c("html", "character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", "character")), message = NULL, post_message = NULL), ids = list(    answer = "question-1-answer", question = "question-1"), loading = structure("<strong>Loading:<\u002fstrong> \nChoose the correct statement:\n<br/><br/><br/>", html = TRUE, class = c("html", "character")), random_answer_order = TRUE, allow_retry = TRUE,     seed = 358562904.333031, options = list()), class = c("learnr_radio", "tutorial_question")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "question-2", question = structure("The \\(\\beta\\) coefficients in a linear model:", html = TRUE, class = c("html", "character")), answers = list(structure(list(id = "lnr_ans_1f925ad",     option = "must enter the model linearly, but predictor variables do not need to enter the model linearly.",     value = "must enter the model linearly, but predictor variables do not need to enter the model linearly.",     label = structure("must enter the model linearly, but predictor variables do not need to enter the model linearly.", html = TRUE, class = c("html",     "character")), correct = TRUE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_953de40",     option = "can enter the model nonlinearly, as can the predictor variables.",     value = "can enter the model nonlinearly, as can the predictor variables.",     label = structure("can enter the model nonlinearly, as can the predictor variables.", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_e11e28c",     option = "can enter the model nonlinearly, but predictor variables must enter the model linearly.",     value = "can enter the model nonlinearly, but predictor variables must enter the model linearly.",     label = structure("can enter the model nonlinearly, but predictor variables must enter the model linearly.", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer"))), button_labels = list(submit = structure("Submit Answer", html = TRUE, class = c("html", "character")), try_again = structure("Try Again", html = TRUE, class = c("html", "character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", "character")), try_again = structure("Incorrect", html = TRUE, class = c("html", "character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", "character")), message = NULL, post_message = NULL), ids = list(    answer = "question-2-answer", question = "question-2"), loading = structure("<strong>Loading:<\u002fstrong> \nThe \\(\\beta\\) coefficients in a linear model:\n<br/><br/><br/>", html = TRUE, class = c("html", "character")), random_answer_order = TRUE, allow_retry = TRUE,     seed = 552704634.742627, options = list()), class = c("learnr_radio", "tutorial_question")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-fit_gala_linear_model-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-fit_gala_linear_model-code-editor`)), session)
output$`tutorial-exercise-fit_gala_linear_model-output` <- renderUI({
  `tutorial-exercise-fit_gala_linear_model-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-get_gala_model_matrix-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-get_gala_model_matrix-code-editor`)), session)
output$`tutorial-exercise-get_gala_model_matrix-output` <- renderUI({
  `tutorial-exercise-get_gala_model_matrix-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-get_gala_response_column-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-get_gala_response_column-code-editor`)), session)
output$`tutorial-exercise-get_gala_response_column-output` <- renderUI({
  `tutorial-exercise-get_gala_response_column-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-calc_gala_inverse_x_trans_x-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-calc_gala_inverse_x_trans_x-code-editor`)), session)
output$`tutorial-exercise-calc_gala_inverse_x_trans_x-output` <- renderUI({
  `tutorial-exercise-calc_gala_inverse_x_trans_x-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gala_betahat_calcs-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gala_betahat_calcs-code-editor`)), session)
output$`tutorial-exercise-gala_betahat_calcs-output` <- renderUI({
  `tutorial-exercise-gala_betahat_calcs-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-lm_object_names-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-lm_object_names-code-editor`)), session)
output$`tutorial-exercise-lm_object_names-output` <- renderUI({
  `tutorial-exercise-lm_object_names-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-summary_of_lm_object_names-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-summary_of_lm_object_names-code-editor`)), session)
output$`tutorial-exercise-summary_of_lm_object_names-output` <- renderUI({
  `tutorial-exercise-summary_of_lm_object_names-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-get_sigma_from_summary_of_lm_object-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-get_sigma_from_summary_of_lm_object-code-editor`)), session)
output$`tutorial-exercise-get_sigma_from_summary_of_lm_object-output` <- renderUI({
  `tutorial-exercise-get_sigma_from_summary_of_lm_object-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-get_coefficients_from_summary_of_lm_object-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-get_coefficients_from_summary_of_lm_object-code-editor`)), session)
output$`tutorial-exercise-get_coefficients_from_summary_of_lm_object-output` <- renderUI({
  `tutorial-exercise-get_coefficients_from_summary_of_lm_object-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "question-3", question = structure("Choose the correct response:", html = TRUE, class = c("html", "character")), answers = list(structure(list(id = "lnr_ans_a3417df",     option = "A", value = "A", label = structure("A", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_1a36d39",     option = "B", value = "B", label = structure("B", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_72a053e",     option = "C", value = "C", label = structure("C", html = TRUE, class = c("html",     "character")), correct = TRUE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_bf3ed0d",     option = "D", value = "D", label = structure("D", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_930975",     option = "None of the above", value = "None of the above",     label = structure("None of the above", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer"))), button_labels = list(submit = structure("Submit Answer", html = TRUE, class = c("html", "character")), try_again = structure("Try Again", html = TRUE, class = c("html", "character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", "character")), try_again = structure("Incorrect", html = TRUE, class = c("html", "character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", "character")), message = NULL, post_message = NULL), ids = list(    answer = "question-3-answer", question = "question-3"), loading = structure("<strong>Loading:<\u002fstrong> \nChoose the correct response:\n<br/><br/><br/>", html = TRUE, class = c("html", "character")), random_answer_order = FALSE, allow_retry = TRUE,     seed = 327995773.847265, options = list()), class = c("learnr_radio", "tutorial_question")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-visualise_residuals_from_summary_of_lm_object-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-visualise_residuals_from_summary_of_lm_object-code-editor`)), session)
output$`tutorial-exercise-visualise_residuals_from_summary_of_lm_object-output` <- renderUI({
  `tutorial-exercise-visualise_residuals_from_summary_of_lm_object-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-anscombes-quartet-summary-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-anscombes-quartet-summary-code-editor`)), session)
output$`tutorial-exercise-anscombes-quartet-summary-output` <- renderUI({
  `tutorial-exercise-anscombes-quartet-summary-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-anscombes-quartet-linear-models-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-anscombes-quartet-linear-models-code-editor`)), session)
output$`tutorial-exercise-anscombes-quartet-linear-models-output` <- renderUI({
  `tutorial-exercise-anscombes-quartet-linear-models-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-anscombes-quartet-linear-models-compare-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-anscombes-quartet-linear-models-compare-code-editor`)), session)
output$`tutorial-exercise-anscombes-quartet-linear-models-compare-output` <- renderUI({
  `tutorial-exercise-anscombes-quartet-linear-models-compare-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-anscombes-quartet-plots-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-anscombes-quartet-plots-code-editor`)), session)
output$`tutorial-exercise-anscombes-quartet-plots-output` <- renderUI({
  `tutorial-exercise-anscombes-quartet-plots-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-fit-nonidentifiable-model-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-fit-nonidentifiable-model-code-editor`)), session)
output$`tutorial-exercise-fit-nonidentifiable-model-output` <- renderUI({
  `tutorial-exercise-fit-nonidentifiable-model-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-check-rank-nonidentifiable-model-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-check-rank-nonidentifiable-model-code-editor`)), session)
output$`tutorial-exercise-check-rank-nonidentifiable-model-output` <- renderUI({
  `tutorial-exercise-check-rank-nonidentifiable-model-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-fit-nearly-nonidentifiable-model-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-fit-nearly-nonidentifiable-model-code-editor`)), session)
output$`tutorial-exercise-fit-nearly-nonidentifiable-model-output` <- renderUI({
  `tutorial-exercise-fit-nearly-nonidentifiable-model-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-f-dist-viz-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-f-dist-viz-1-code-editor`)), session)
output$`tutorial-exercise-f-dist-viz-1-output` <- renderUI({
  `tutorial-exercise-f-dist-viz-1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-f-dist-2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-f-dist-2-code-editor`)), session)
output$`tutorial-exercise-f-dist-2-output` <- renderUI({
  `tutorial-exercise-f-dist-2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gala-anova-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gala-anova-code-editor`)), session)
output$`tutorial-exercise-gala-anova-output` <- renderUI({
  `tutorial-exercise-gala-anova-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gala-anova-step-by-step-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gala-anova-step-by-step-1-code-editor`)), session)
output$`tutorial-exercise-gala-anova-step-by-step-1-output` <- renderUI({
  `tutorial-exercise-gala-anova-step-by-step-1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-anova-test-one-variable-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-anova-test-one-variable-code-editor`)), session)
output$`tutorial-exercise-anova-test-one-variable-output` <- renderUI({
  `tutorial-exercise-anova-test-one-variable-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-t-test-same-as-anova-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-t-test-same-as-anova-code-editor`)), session)
output$`tutorial-exercise-t-test-same-as-anova-output` <- renderUI({
  `tutorial-exercise-t-test-same-as-anova-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gala-sig-in-different-models-activity-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gala-sig-in-different-models-activity-code-editor`)), session)
output$`tutorial-exercise-gala-sig-in-different-models-activity-output` <- renderUI({
  `tutorial-exercise-gala-sig-in-different-models-activity-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-two-vars-test-activity-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-two-vars-test-activity-code-editor`)), session)
output$`tutorial-exercise-two-vars-test-activity-output` <- renderUI({
  `tutorial-exercise-two-vars-test-activity-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-subspace-testing-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-subspace-testing-1-code-editor`)), session)
output$`tutorial-exercise-subspace-testing-1-output` <- renderUI({
  `tutorial-exercise-subspace-testing-1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-subspace-testing-2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-subspace-testing-2-code-editor`)), session)
output$`tutorial-exercise-subspace-testing-2-output` <- renderUI({
  `tutorial-exercise-subspace-testing-2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gala-perm-test-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gala-perm-test-1-code-editor`)), session)
output$`tutorial-exercise-gala-perm-test-1-output` <- renderUI({
  `tutorial-exercise-gala-perm-test-1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gala-perm-test-2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gala-perm-test-2-code-editor`)), session)
output$`tutorial-exercise-gala-perm-test-2-output` <- renderUI({
  `tutorial-exercise-gala-perm-test-2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gala-perm-test-3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gala-perm-test-3-code-editor`)), session)
output$`tutorial-exercise-gala-perm-test-3-output` <- renderUI({
  `tutorial-exercise-gala-perm-test-3-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gala-perm-test-4-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gala-perm-test-4-code-editor`)), session)
output$`tutorial-exercise-gala-perm-test-4-output` <- renderUI({
  `tutorial-exercise-gala-perm-test-4-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gala-perm-test-5-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gala-perm-test-5-code-editor`)), session)
output$`tutorial-exercise-gala-perm-test-5-output` <- renderUI({
  `tutorial-exercise-gala-perm-test-5-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gala-perm-test-6-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gala-perm-test-6-code-editor`)), session)
output$`tutorial-exercise-gala-perm-test-6-output` <- renderUI({
  `tutorial-exercise-gala-perm-test-6-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-conf-ints-5-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-conf-ints-5-code-editor`)), session)
output$`tutorial-exercise-conf-ints-5-output` <- renderUI({
  `tutorial-exercise-conf-ints-5-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-conf-ints-6-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-conf-ints-6-code-editor`)), session)
output$`tutorial-exercise-conf-ints-6-output` <- renderUI({
  `tutorial-exercise-conf-ints-6-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-bootstrap-ci-2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-bootstrap-ci-2-code-editor`)), session)
output$`tutorial-exercise-bootstrap-ci-2-output` <- renderUI({
  `tutorial-exercise-bootstrap-ci-2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-bootstrap-ci-3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-bootstrap-ci-3-code-editor`)), session)
output$`tutorial-exercise-bootstrap-ci-3-output` <- renderUI({
  `tutorial-exercise-bootstrap-ci-3-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-bootstrap-ci-4-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-bootstrap-ci-4-code-editor`)), session)
output$`tutorial-exercise-bootstrap-ci-4-output` <- renderUI({
  `tutorial-exercise-bootstrap-ci-4-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-mle-lm-fit-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-mle-lm-fit-1-code-editor`)), session)
output$`tutorial-exercise-mle-lm-fit-1-output` <- renderUI({
  `tutorial-exercise-mle-lm-fit-1-result`()
})
</script>
 <!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.11"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.11"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.11"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.11"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.11"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.11"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44]}},"value":[{"type":"character","attributes":{},"value":["backports","base","bslib","checkmate","compiler","datasets","digest","ellipsis","evaluate","fastmap","graphics","grDevices","highr","htmltools","htmlwidgets","httpuv","jquerylib","jsonlite","knitr","later","learnr","lifecycle","magrittr","markdown","methods","mime","promises","R6","Rcpp","rlang","rmarkdown","rprojroot","sass","shiny","stats","stringi","stringr","tools","utils","vctrs","withr","xfun","xtable","yaml"]},{"type":"character","attributes":{},"value":["1.4.1","4.0.3","0.3.1","2.0.0","4.0.3","4.0.3","0.6.29","0.3.2","0.14","1.1.0","4.0.3","4.0.3","0.9","0.5.2","1.5.4","1.6.5","0.1.4","1.7.3","1.37","1.3.0","0.10.1","1.0.1","2.0.1","1.1","4.0.3","0.12","1.2.0.1","2.5.1","1.0.7","0.4.12","2.11","2.0.2","0.4.0","1.7.1","4.0.3","1.7.6","1.4.0","4.0.3","4.0.3","0.3.8","2.4.3","0.29","1.8-4","2.2.1"]}]}]}
</script>
<!--/html_preserve-->
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">HDAT9600 Linear Models 1</h2>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->




<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
